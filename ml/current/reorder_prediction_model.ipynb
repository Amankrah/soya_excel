{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Client Reorder Prediction Model\n",
    "## Predicting Next Order Date for Small (0-5 TM) and Medium (5-10 TM) Orders\n",
    "\n",
    "**Objective**: Build ML models to predict when a client will place their next order\n",
    "\n",
    "**Target Categories**:\n",
    "- Small Orders: 0-5 TM\n",
    "- Medium Orders: 5-10 TM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn xgboost openpyxl tensorflow keras -q\n",
    "\n",
    "print(\"All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import xgboost as xgb\n",
    "\n",
    "# Deep Learning libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Bidirectional, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_excel('soya_data_cleaned_2023_onwards.xlsx')\n",
    "\n",
    "# Convert date columns\n",
    "date_columns = ['sales_order_creation_date', 'promised_expedition_date', 'actual_expedition_date', 'date_and_time_expedition']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nDate range: {df['actual_expedition_date'].min()} to {df['actual_expedition_date'].max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Order Size Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create order size categories\n",
    "df['order_size_category'] = pd.cut(\n",
    "    df['total_amount_delivered_tm'],\n",
    "    bins=[0, 5, 10, 20, np.inf],\n",
    "    labels=['Small', 'Medium', 'Large', 'Extra Large'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "print(\"Order Size Distribution:\")\n",
    "print(df['order_size_category'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df['order_size_category'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filter for Small and Medium Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Small and Medium orders only\n",
    "df_filtered = df[df['order_size_category'].isin(['Small', 'Medium'])].copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "print(f\"Filtered dataset (Small + Medium): {len(df_filtered)} records\")\n",
    "print(f\"\\nCategory breakdown:\")\n",
    "print(df_filtered['order_size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Preparation - Calculate Reorder Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure unique SO numbers by deduplicating client_order_number\n",
    "print(f\"Before deduplication: {len(df_filtered)} records\")\n",
    "print(f\"Unique client_order_numbers: {df_filtered['client_order_number'].nunique()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df_filtered['client_order_number'].duplicated().sum()\n",
    "print(f\"Duplicate SO numbers found: {duplicates}\")\n",
    "\n",
    "# Keep only the first occurrence of each client_order_number\n",
    "# (assuming first record is the most accurate)\n",
    "df_filtered = df_filtered.drop_duplicates(subset='client_order_number', keep='first')\n",
    "\n",
    "print(f\"After deduplication: {len(df_filtered)} records\")\n",
    "print()\n",
    "\n",
    "# Sort by client and date\n",
    "df_filtered = df_filtered.sort_values(['client_name', 'actual_expedition_date'])\n",
    "\n",
    "# Calculate days since last order for each client\n",
    "df_filtered['days_since_last_order'] = df_filtered.groupby('client_name')['actual_expedition_date'].diff().dt.days\n",
    "\n",
    "# Create next order date (target variable)\n",
    "df_filtered['next_order_date'] = df_filtered.groupby('client_name')['actual_expedition_date'].shift(-1)\n",
    "df_filtered['days_until_next_order'] = (df_filtered['next_order_date'] - df_filtered['actual_expedition_date']).dt.days\n",
    "\n",
    "print(\"Days until next order - Statistics:\")\n",
    "print(df_filtered['days_until_next_order'].describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "df_filtered['days_until_next_order'].hist(bins=50, edgecolor='black')\n",
    "plt.xlabel('Days Until Next Order')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Days Until Next Order')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "df_filtered.boxplot(column='days_until_next_order', by='order_size_category')\n",
    "plt.xlabel('Order Size Category')\n",
    "plt.ylabel('Days Until Next Order')\n",
    "plt.title('Reorder Time by Category')\n",
    "plt.suptitle('')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client-level features\n",
    "client_features = df_filtered.groupby('client_name').agg({\n",
    "    'total_amount_delivered_tm': ['mean', 'std', 'min', 'max', 'count'],\n",
    "    'days_since_last_order': ['mean', 'std', 'median'],\n",
    "    'actual_expedition_date': ['min', 'max']\n",
    "}).reset_index()\n",
    "\n",
    "client_features.columns = ['_'.join(col).strip('_') for col in client_features.columns.values]\n",
    "client_features.rename(columns={'client_name': 'client_name'}, inplace=True)\n",
    "\n",
    "# Calculate client lifetime (days active)\n",
    "client_features['client_lifetime_days'] = (\n",
    "    client_features['actual_expedition_date_max'] - client_features['actual_expedition_date_min']\n",
    ").dt.days\n",
    "\n",
    "# Calculate order frequency (orders per month)\n",
    "client_features['order_frequency_per_month'] = (\n",
    "    client_features['total_amount_delivered_tm_count'] / \n",
    "    (client_features['client_lifetime_days'] / 30)\n",
    ")\n",
    "\n",
    "print(\"Client Features Created:\")\n",
    "print(client_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order-level features\n",
    "df_features = df_filtered.copy()\n",
    "\n",
    "# Time-based features\n",
    "df_features['order_month'] = df_features['actual_expedition_date'].dt.month\n",
    "df_features['order_quarter'] = df_features['actual_expedition_date'].dt.quarter\n",
    "df_features['order_day_of_week'] = df_features['actual_expedition_date'].dt.dayofweek\n",
    "df_features['order_day_of_month'] = df_features['actual_expedition_date'].dt.day\n",
    "df_features['is_weekend'] = df_features['order_day_of_week'].isin([5, 6]).astype(int)\n",
    "\n",
    "# Client order sequence\n",
    "df_features['order_sequence'] = df_features.groupby('client_name').cumcount() + 1\n",
    "\n",
    "# Recency, Frequency, Monetary (RFM) features\n",
    "current_date = df_features['actual_expedition_date'].max()\n",
    "df_features['recency_days'] = (current_date - df_features['actual_expedition_date']).dt.days\n",
    "\n",
    "# Product-based features\n",
    "df_features['product_encoded'] = LabelEncoder().fit_transform(df_features['product_name'].fillna('Unknown'))\n",
    "\n",
    "# Rolling window features (last 3 orders per client)\n",
    "df_features['rolling_avg_quantity_3'] = df_features.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).mean()\n",
    ")\n",
    "df_features['rolling_std_quantity_3'] = df_features.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).std()\n",
    ").fillna(0)\n",
    "\n",
    "print(f\"\\nFeature engineering complete. Total features: {df_features.shape[1]}\")\n",
    "print(\"\\nSample features:\")\n",
    "print(df_features[['client_name', 'order_sequence', 'order_month', 'rolling_avg_quantity_3', 'days_until_next_order']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Merge Client Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge client-level features\n",
    "df_features = df_features.merge(client_features, on='client_name', how='left')\n",
    "\n",
    "print(f\"Dataset shape after merging: {df_features.shape}\")\n",
    "print(f\"\\nColumns: {df_features.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Prepare Modeling Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where we don't have a next order (last order for each client)\n",
    "df_model = df_features[df_features['days_until_next_order'].notna()].copy()\n",
    "\n",
    "# Remove outliers (optional - orders with extremely long reorder times)\n",
    "# Keep reorder times within reasonable range (e.g., < 365 days)\n",
    "df_model = df_model[df_model['days_until_next_order'] <= 365]\n",
    "\n",
    "print(f\"Modeling dataset size: {len(df_model)} records\")\n",
    "print(f\"Target variable (days_until_next_order) statistics:\")\n",
    "print(df_model['days_until_next_order'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for modeling\n",
    "feature_columns = [\n",
    "    # Order-level features\n",
    "    'total_amount_delivered_tm',\n",
    "    'order_sequence',\n",
    "    'order_month',\n",
    "    'order_quarter',\n",
    "    'order_day_of_week',\n",
    "    'is_weekend',\n",
    "    'days_since_last_order',\n",
    "    'product_encoded',\n",
    "    'rolling_avg_quantity_3',\n",
    "    'rolling_std_quantity_3',\n",
    "    \n",
    "    # Client-level features\n",
    "    'total_amount_delivered_tm_mean',\n",
    "    'total_amount_delivered_tm_std',\n",
    "    'total_amount_delivered_tm_count',\n",
    "    'days_since_last_order_mean',\n",
    "    'days_since_last_order_std',\n",
    "    'client_lifetime_days',\n",
    "    'order_frequency_per_month'\n",
    "]\n",
    "\n",
    "# Create X and y\n",
    "X = df_model[feature_columns].fillna(0)\n",
    "y = df_model['days_until_next_order']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeatures used: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.5 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze reorder time patterns\n",
    "print(\"=\"*80)\n",
    "print(\"REORDER TIME DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate statistics\n",
    "same_day = (df_model['days_until_next_order'] == 0).sum()\n",
    "next_day = (df_model['days_until_next_order'] == 1).sum()\n",
    "within_week = (df_model['days_until_next_order'] <= 7).sum()\n",
    "long_term = (df_model['days_until_next_order'] > 30).sum()\n",
    "\n",
    "total = len(df_model)\n",
    "\n",
    "print(f\"\\nTotal orders analyzed: {total:,}\")\n",
    "print(f\"\\nReorder time breakdown:\")\n",
    "print(f\"  Same day (0 days):     {same_day:,} orders ({same_day/total*100:.1f}%)\")\n",
    "print(f\"  Next day (1 day):      {next_day:,} orders ({next_day/total*100:.1f}%)\")\n",
    "print(f\"  Within week (≤7 days): {within_week:,} orders ({within_week/total*100:.1f}%)\")\n",
    "print(f\"  Long term (>30 days):  {long_term:,} orders ({long_term/total*100:.1f}%)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze same-day reorders by client\n",
    "same_day_clients = df_model[df_model['days_until_next_order'] == 0].groupby('client_name').size()\n",
    "same_day_clients = same_day_clients.sort_values(ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SAME-DAY REORDER ANALYSIS (Top 10 Clients)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Note: These may be middlemen ordering multiple times for different end clients\")\n",
    "print(f\"\\nTop 10 clients with most same-day reorders:\")\n",
    "for idx, (client, count) in enumerate(same_day_clients.head(10).items(), 1):\n",
    "    total_orders = len(df_model[df_model['client_name'] == client])\n",
    "    print(f\"  {idx}. {client[:45]:45s} - {count:3d} same-day reorders ({count/total_orders*100:.0f}% of their orders)\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Full distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(df_model['days_until_next_order'], bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "ax1.set_xlabel('Days Until Next Order', fontsize=11)\n",
    "ax1.set_ylabel('Frequency', fontsize=11)\n",
    "ax1.set_title('Full Distribution of Reorder Times', fontweight='bold', fontsize=12)\n",
    "ax1.axvline(df_model['days_until_next_order'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df_model[\"days_until_next_order\"].mean():.1f} days')\n",
    "ax1.axvline(df_model['days_until_next_order'].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df_model[\"days_until_next_order\"].median():.1f} days')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "# 2. Zoomed view (0-30 days)\n",
    "ax2 = axes[0, 1]\n",
    "short_term = df_model[df_model['days_until_next_order'] <= 30]['days_until_next_order']\n",
    "ax2.hist(short_term, bins=30, edgecolor='black', alpha=0.7, color='coral')\n",
    "ax2.set_xlabel('Days Until Next Order', fontsize=11)\n",
    "ax2.set_ylabel('Frequency', fontsize=11)\n",
    "ax2.set_title('Zoomed: 0-30 Days (Short-term Reorders)', fontweight='bold', fontsize=12)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. Box plot by order category\n",
    "ax3 = axes[1, 0]\n",
    "small_orders = df_model[df_model['total_amount_delivered_tm'] <= 5]['days_until_next_order']\n",
    "medium_orders = df_model[(df_model['total_amount_delivered_tm'] > 5) & (df_model['total_amount_delivered_tm'] <= 10)]['days_until_next_order']\n",
    "ax3.boxplot([small_orders, medium_orders], labels=['Small (0-5 TM)', 'Medium (5-10 TM)'])\n",
    "ax3.set_ylabel('Days Until Next Order', fontsize=11)\n",
    "ax3.set_title('Reorder Time by Order Size Category', fontweight='bold', fontsize=12)\n",
    "ax3.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 4. Cumulative distribution\n",
    "ax4 = axes[1, 1]\n",
    "sorted_days = np.sort(df_model['days_until_next_order'])\n",
    "cumulative = np.arange(1, len(sorted_days) + 1) / len(sorted_days) * 100\n",
    "ax4.plot(sorted_days, cumulative, linewidth=2, color='purple')\n",
    "ax4.set_xlabel('Days Until Next Order', fontsize=11)\n",
    "ax4.set_ylabel('Cumulative Percentage (%)', fontsize=11)\n",
    "ax4.set_title('Cumulative Distribution Function', fontweight='bold', fontsize=12)\n",
    "ax4.grid(alpha=0.3)\n",
    "ax4.axhline(50, color='red', linestyle='--', alpha=0.5, label='50th percentile')\n",
    "ax4.axhline(75, color='orange', linestyle='--', alpha=0.5, label='75th percentile')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"INTERPRETATION:\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"✓ Same-day (0) and next-day (1) reorders are common - likely middlemen\")\n",
    "print(f\"✓ This is NORMAL business behavior and should be included in the model\")\n",
    "print(f\"✓ The model will learn to distinguish between:\")\n",
    "print(f\"  - High-frequency clients (middlemen): Predict short reorder times\")\n",
    "print(f\"  - Regular clients: Predict longer reorder cycles\")\n",
    "print(f\"✓ Features like 'order_frequency_per_month' and 'days_since_last_order_mean'\")\n",
    "print(f\"  will help the model identify client types\")\n",
    "print(f\"{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean infinite and very large values\n",
    "print(\"Checking for infinite values...\")\n",
    "print(f\"Infinite values before cleaning: {np.isinf(X.values).sum()}\")\n",
    "\n",
    "# Replace inf values with a reasonable maximum\n",
    "X = X.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "# Check for any remaining issues\n",
    "print(f\"Infinite values after cleaning: {np.isinf(X.values).sum()}\")\n",
    "print(f\"NaN values: {X.isna().sum().sum()}\")\n",
    "print(f\"\\nData is ready for modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TRAIN-TEST SPLIT STRATEGY ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# OPTION 1: Time-Based Split (Recommended for production)\n",
    "# Train on older data, test on recent data (simulates real-world deployment)\n",
    "print(\"\\nOption 1: TIME-BASED SPLIT (Most Realistic)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Sort by date\n",
    "df_model_sorted = df_model.sort_values('actual_expedition_date')\n",
    "split_point = int(len(df_model_sorted) * 0.8)\n",
    "\n",
    "train_idx_time = df_model_sorted.index[:split_point]\n",
    "test_idx_time = df_model_sorted.index[split_point:]\n",
    "\n",
    "cutoff_date = df_model_sorted.iloc[split_point]['actual_expedition_date']\n",
    "print(f\"Training: Orders before {cutoff_date.date()}\")\n",
    "print(f\"Testing:  Orders from {cutoff_date.date()} onwards\")\n",
    "print(f\"Train size: {len(train_idx_time)} ({len(train_idx_time)/len(df_model)*100:.1f}%)\")\n",
    "print(f\"Test size:  {len(test_idx_time)} ({len(test_idx_time)/len(df_model)*100:.1f}%)\")\n",
    "\n",
    "# OPTION 2: Client-Based Split (Prevents client data leakage)\n",
    "print(\"\\n\\nOption 2: CLIENT-BASED SPLIT (Best Generalization)\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Get unique clients\n",
    "unique_clients = df_model['client_name'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_clients)\n",
    "\n",
    "split_point_clients = int(len(unique_clients) * 0.8)\n",
    "train_clients = unique_clients[:split_point_clients]\n",
    "test_clients = unique_clients[split_point_clients:]\n",
    "\n",
    "train_idx_client = df_model[df_model['client_name'].isin(train_clients)].index\n",
    "test_idx_client = df_model[df_model['client_name'].isin(test_clients)].index\n",
    "\n",
    "print(f\"Training: {len(train_clients)} clients, {len(train_idx_client)} orders\")\n",
    "print(f\"Testing:  {len(test_clients)} clients, {len(test_idx_client)} orders\")\n",
    "print(f\"Train size: {len(train_idx_client)} ({len(train_idx_client)/len(df_model)*100:.1f}%)\")\n",
    "print(f\"Test size:  {len(test_idx_client)} ({len(test_idx_client)/len(df_model)*100:.1f}%)\")\n",
    "\n",
    "# OPTION 3: Hybrid - Stratified Client Split (RECOMMENDED)\n",
    "print(\"\\n\\nOption 3: HYBRID SPLIT - Stratified by Client (RECOMMENDED)\")\n",
    "print(\"-\" * 60)\n",
    "print(\"Strategy: For each client, use 80% of their orders for training,\")\n",
    "print(\"          20% of their most recent orders for testing\")\n",
    "print()\n",
    "\n",
    "# For each client, split their orders chronologically\n",
    "train_indices_hybrid = []\n",
    "test_indices_hybrid = []\n",
    "\n",
    "for client in df_model['client_name'].unique():\n",
    "    client_orders = df_model[df_model['client_name'] == client].sort_values('actual_expedition_date')\n",
    "    n_orders = len(client_orders)\n",
    "    \n",
    "    if n_orders == 1:\n",
    "        # If only 1 order, put in training\n",
    "        train_indices_hybrid.extend(client_orders.index.tolist())\n",
    "    else:\n",
    "        # Split: 80% train, 20% test (rounded)\n",
    "        split_idx = max(1, int(n_orders * 0.8))\n",
    "        train_indices_hybrid.extend(client_orders.index[:split_idx].tolist())\n",
    "        test_indices_hybrid.extend(client_orders.index[split_idx:].tolist())\n",
    "\n",
    "train_idx_hybrid = train_indices_hybrid\n",
    "test_idx_hybrid = test_indices_hybrid\n",
    "\n",
    "# Verify client overlap\n",
    "train_clients_hybrid = df_model.loc[train_idx_hybrid, 'client_name'].unique()\n",
    "test_clients_hybrid = df_model.loc[test_idx_hybrid, 'client_name'].unique()\n",
    "overlap_clients = set(train_clients_hybrid).intersection(set(test_clients_hybrid))\n",
    "\n",
    "print(f\"Train size: {len(train_idx_hybrid)} ({len(train_idx_hybrid)/len(df_model)*100:.1f}%)\")\n",
    "print(f\"Test size:  {len(test_idx_hybrid)} ({len(test_idx_hybrid)/len(df_model)*100:.1f}%)\")\n",
    "print(f\"Clients in training: {len(train_clients_hybrid)}\")\n",
    "print(f\"Clients in testing: {len(test_clients_hybrid)}\")\n",
    "print(f\"Client overlap: {len(overlap_clients)} (acceptable - testing on future orders)\")\n",
    "\n",
    "# Let user choose the split strategy\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SELECTING SPLIT STRATEGY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# For this analysis, we'll use OPTION 3 (Hybrid) as it's most robust\n",
    "SPLIT_STRATEGY = 'client'  # Options: 'random', 'time', 'client', 'hybrid'\n",
    "\n",
    "if SPLIT_STRATEGY == 'time':\n",
    "    train_idx, test_idx = train_idx_time, test_idx_time\n",
    "    print(\"✓ Using TIME-BASED split\")\n",
    "elif SPLIT_STRATEGY == 'client':\n",
    "    train_idx, test_idx = train_idx_client, test_idx_client\n",
    "    print(\"✓ Using CLIENT-BASED split\")\n",
    "elif SPLIT_STRATEGY == 'hybrid':\n",
    "    train_idx, test_idx = train_idx_hybrid, test_idx_hybrid\n",
    "    print(\"✓ Using HYBRID (Time + Client) split\")\n",
    "else:  # random\n",
    "    train_idx, test_idx = train_test_split(df_model.index, test_size=0.2, random_state=42)\n",
    "    print(\"✓ Using RANDOM split (baseline)\")\n",
    "\n",
    "# Create train-test splits\n",
    "X_train = X.loc[train_idx]\n",
    "X_test = X.loc[test_idx]\n",
    "y_train = y.loc[train_idx]\n",
    "y_test = y.loc[test_idx]\n",
    "\n",
    "print(f\"\\nFinal split: {len(X_train)} train / {len(X_test)} test\")\n",
    "\n",
    "# Verify split integrity\n",
    "if SPLIT_STRATEGY == 'hybrid':\n",
    "    train_clients_final = df_model.loc[train_idx, 'client_name'].unique()\n",
    "    test_clients_final = df_model.loc[test_idx, 'client_name'].unique()\n",
    "    overlap = set(train_clients_final).intersection(set(test_clients_final))\n",
    "    print(f\"✓ Client overlap: {len(overlap)} clients in both sets\")\n",
    "    print(f\"  (Expected for stratified split - testing on future orders)\")\n",
    "elif SPLIT_STRATEGY == 'client':\n",
    "    train_clients_final = df_model.loc[train_idx, 'client_name'].unique()\n",
    "    test_clients_final = df_model.loc[test_idx, 'client_name'].unique()\n",
    "    overlap = set(train_clients_final).intersection(set(test_clients_final))\n",
    "    print(f\"✓ Client overlap check: {len(overlap)} clients (should be 0 for client-based split)\")\n",
    "\n",
    "# Scale features for traditional ML models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# MinMax scaling for LSTM (scales to 0-1 range)\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_minmax = minmax_scaler.fit_transform(X_train)\n",
    "X_test_minmax = minmax_scaler.transform(X_test)\n",
    "\n",
    "# Reshape for LSTM (samples, timesteps, features)\n",
    "X_train_lstm = X_train_minmax.reshape((X_train_minmax.shape[0], 1, X_train_minmax.shape[1]))\n",
    "X_test_lstm = X_test_minmax.reshape((X_test_minmax.shape[0], 1, X_test_minmax.shape[1]))\n",
    "\n",
    "print(f\"\\nScaled data ready:\")\n",
    "print(f\"  Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"  Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"  LSTM input shape: {X_train_lstm.shape}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Target distribution in training set:\")\n",
    "print(y_train.describe())\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the split quality - show example for one client\n",
    "print(\"=\"*80)\n",
    "print(\"SPLIT VERIFICATION - Example Client Analysis\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Pick a client with multiple orders\n",
    "example_client = df_model.groupby('client_name').size().sort_values(ascending=False).head(5).index[0]\n",
    "client_data = df_model[df_model['client_name'] == example_client].sort_values('actual_expedition_date')\n",
    "\n",
    "# Check which orders are in train vs test\n",
    "client_train = client_data.index.isin(train_idx)\n",
    "client_test = client_data.index.isin(test_idx)\n",
    "\n",
    "print(f\"\\nExample Client: {example_client}\")\n",
    "print(f\"Total Orders: {len(client_data)}\")\n",
    "print(f\"Training Orders: {client_train.sum()} (earliest orders)\")\n",
    "print(f\"Testing Orders: {client_test.sum()} (most recent orders)\")\n",
    "\n",
    "if len(client_data) > 0:\n",
    "    train_dates = client_data[client_train]['actual_expedition_date']\n",
    "    test_dates = client_data[client_test]['actual_expedition_date']\n",
    "    \n",
    "    if len(train_dates) > 0:\n",
    "        print(f\"\\nTraining date range: {train_dates.min().date()} to {train_dates.max().date()}\")\n",
    "    if len(test_dates) > 0:\n",
    "        print(f\"Testing date range:  {test_dates.min().date()} to {test_dates.max().date()}\")\n",
    "        print(f\"\\n✓ Correct: Test orders are AFTER train orders (time-aware)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Your model will:\")\n",
    "print(\"  1. Learn from each client's PAST orders (training set)\")\n",
    "print(\"  2. Predict their FUTURE reorders (testing set)\")\n",
    "print(\"  3. This mimics real-world production usage perfectly!\")\n",
    "print(\"\\n✓ Split quality:\")\n",
    "print(f\"  - Balanced: {len(train_idx)}/{len(test_idx)} (~80/20)\")\n",
    "print(f\"  - Time-aware: Testing on chronologically future orders\")\n",
    "print(f\"  - Realistic: Same clients but predicting their next orders\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different split strategies\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "# 1. Time-based split visualization\n",
    "ax1 = axes[0, 0]\n",
    "train_dates_time = df_model.loc[train_idx_time, 'actual_expedition_date']\n",
    "test_dates_time = df_model.loc[test_idx_time, 'actual_expedition_date']\n",
    "ax1.hist([train_dates_time, test_dates_time], bins=30, label=['Train', 'Test'], \n",
    "         color=['steelblue', 'orange'], alpha=0.7, stacked=False)\n",
    "ax1.set_xlabel('Order Date', fontsize=10)\n",
    "ax1.set_ylabel('Number of Orders', fontsize=10)\n",
    "ax1.set_title('Option 1: Time-Based Split\\n(Train on old data, test on recent)', fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "plt.setp(ax1.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 2. Client-based split visualization\n",
    "ax2 = axes[0, 1]\n",
    "train_clients_client = df_model.loc[train_idx_client, 'client_name'].nunique()\n",
    "test_clients_client = df_model.loc[test_idx_client, 'client_name'].nunique()\n",
    "bars = ax2.bar(['Train Clients', 'Test Clients'], \n",
    "               [train_clients_client, test_clients_client],\n",
    "               color=['steelblue', 'orange'], alpha=0.7)\n",
    "ax2.set_ylabel('Number of Unique Clients', fontsize=10)\n",
    "ax2.set_title('Option 2: Client-Based Split\\n(Different clients in train vs test)', fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height,\n",
    "            f'{int(height)}',\n",
    "            ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 3. Hybrid split visualization\n",
    "ax3 = axes[1, 0]\n",
    "train_dates_hybrid = df_model.loc[train_idx_hybrid, 'actual_expedition_date']\n",
    "test_dates_hybrid = df_model.loc[test_idx_hybrid, 'actual_expedition_date']\n",
    "ax3.hist([train_dates_hybrid, test_dates_hybrid], bins=30, label=['Train', 'Test'], \n",
    "         color=['steelblue', 'orange'], alpha=0.7, stacked=False)\n",
    "ax3.set_xlabel('Order Date', fontsize=10)\n",
    "ax3.set_ylabel('Number of Orders', fontsize=10)\n",
    "ax3.set_title('Option 3: Hybrid Split (RECOMMENDED)\\n(Time-based + No client overlap)', fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(alpha=0.3)\n",
    "plt.setp(ax3.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
    "\n",
    "# 4. Comparison table\n",
    "ax4 = axes[1, 1]\n",
    "ax4.axis('off')\n",
    "\n",
    "# Calculate metrics for each strategy\n",
    "comparison_data = []\n",
    "\n",
    "# Random (baseline)\n",
    "random_train, random_test = train_test_split(df_model.index, test_size=0.2, random_state=42)\n",
    "random_train_clients = df_model.loc[random_train, 'client_name'].nunique()\n",
    "random_test_clients = df_model.loc[random_test, 'client_name'].nunique()\n",
    "random_overlap = len(set(df_model.loc[random_train, 'client_name']).intersection(\n",
    "                    set(df_model.loc[random_test, 'client_name'])))\n",
    "\n",
    "comparison_data.append(['Random', len(random_train), len(random_test), \n",
    "                       random_train_clients, random_test_clients, random_overlap])\n",
    "\n",
    "# Time-based\n",
    "time_train_clients = df_model.loc[train_idx_time, 'client_name'].nunique()\n",
    "time_test_clients = df_model.loc[test_idx_time, 'client_name'].nunique()\n",
    "time_overlap = len(set(df_model.loc[train_idx_time, 'client_name']).intersection(\n",
    "                   set(df_model.loc[test_idx_time, 'client_name'])))\n",
    "\n",
    "comparison_data.append(['Time-Based', len(train_idx_time), len(test_idx_time),\n",
    "                       time_train_clients, time_test_clients, time_overlap])\n",
    "\n",
    "# Client-based\n",
    "comparison_data.append(['Client-Based', len(train_idx_client), len(test_idx_client),\n",
    "                       train_clients_client, test_clients_client, 0])\n",
    "\n",
    "# Hybrid\n",
    "hybrid_train_clients = df_model.loc[train_idx_hybrid, 'client_name'].nunique()\n",
    "hybrid_test_clients = df_model.loc[test_idx_hybrid, 'client_name'].nunique()\n",
    "comparison_data.append(['Hybrid', len(train_idx_hybrid), len(test_idx_hybrid),\n",
    "                       hybrid_train_clients, hybrid_test_clients, 0])\n",
    "\n",
    "comparison_text = \"\"\"\n",
    "SPLIT STRATEGY COMPARISON\n",
    "═════════════════════════════════════════\n",
    "\n",
    "Strategy        Train    Test   Clients  Overlap\n",
    "                Orders   Orders (Train/Test)\n",
    "─────────────────────────────────────────\n",
    "Random          {0[1]:<6}   {0[2]:<6}  {0[3]}/{0[4]:<4}   {0[5]:<4}\n",
    "Time-Based      {1[1]:<6}   {1[2]:<6}  {1[3]}/{1[4]:<4}   {1[5]:<4}\n",
    "Client-Based    {2[1]:<6}   {2[2]:<6}  {2[3]}/{2[4]:<4}   {2[5]:<4}\n",
    "Hybrid ✓        {3[1]:<6}   {3[2]:<6}  {3[3]}/{3[4]:<4}   {3[5]:<4}\n",
    "\n",
    "RECOMMENDATIONS:\n",
    "─────────────────────────────────────────\n",
    "• HYBRID (Stratified): BEST for production\n",
    "  - Each client: 80% train, 20% test\n",
    "  - Time-aware per client\n",
    "  - Balanced 80/20 split\n",
    "  - Tests on recent orders per client\n",
    "\n",
    "• TIME-BASED: Good alternative\n",
    "  - Tests on recent data\n",
    "  - Has client overlap\n",
    "\n",
    "• CLIENT-BASED: For new client testing\n",
    "  - Tests on completely unseen clients\n",
    "  - Imbalanced split\n",
    "\n",
    "• RANDOM: Baseline only\n",
    "  - Data leakage risk\n",
    "  - Not recommended\n",
    "\n",
    "CURRENT SELECTION: {4}\n",
    "\"\"\".format(*comparison_data, SPLIT_STRATEGY.upper())\n",
    "\n",
    "ax4.text(0.05, 0.95, comparison_text, transform=ax4.transAxes, fontsize=9,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.2))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RECOMMENDATION FOR YOUR DATA SIZE (~3,500 samples):\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ HYBRID (Stratified by Client) is RECOMMENDED because:\")\n",
    "print(\"  1. Each client contributes 80% to train, 20% to test\")\n",
    "print(\"  2. Maintains balanced 80/20 overall split\")\n",
    "print(\"  3. Time-aware: tests on each client's FUTURE orders\")\n",
    "print(\"  4. Realistic: predicts next order based on past orders\")\n",
    "print(\"  5. Prevents overfitting to specific clients\")\n",
    "print(\"\\n✓ This approach:\")\n",
    "print(\"  - Ensures adequate test set size (unlike pure time+client split)\")\n",
    "print(\"  - Tests model's ability to predict NEXT order for existing clients\")\n",
    "print(\"  - Perfect for your reorder prediction use case!\")\n",
    "print(\"\\n✓ Alternative: Use 'time' if you want to test on purely recent data\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store results for all models\n",
    "results = []\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TRAINING ADVANCED ML MODELS\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.1 XGBoost with Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training XGBoost with Hyperparameter Tuning...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 10],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search_xgb = GridSearchCV(\n",
    "    xgb_model, \n",
    "    param_grid_xgb, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search_xgb.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb = grid_search_xgb.best_estimator_\n",
    "print(f\"\\nBest parameters: {grid_search_xgb.best_params_}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_xgb = best_xgb.predict(X_train)\n",
    "y_pred_test_xgb = best_xgb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_mae_xgb = mean_absolute_error(y_train, y_pred_train_xgb)\n",
    "test_mae_xgb = mean_absolute_error(y_test, y_pred_test_xgb)\n",
    "train_rmse_xgb = np.sqrt(mean_squared_error(y_train, y_pred_train_xgb))\n",
    "test_rmse_xgb = np.sqrt(mean_squared_error(y_test, y_pred_test_xgb))\n",
    "train_r2_xgb = r2_score(y_train, y_pred_train_xgb)\n",
    "test_r2_xgb = r2_score(y_test, y_pred_test_xgb)\n",
    "\n",
    "print(f\"\\nTrain MAE: {train_mae_xgb:.2f} days\")\n",
    "print(f\"Test MAE: {test_mae_xgb:.2f} days\")\n",
    "print(f\"Train RMSE: {train_rmse_xgb:.2f} days\")\n",
    "print(f\"Test RMSE: {test_rmse_xgb:.2f} days\")\n",
    "print(f\"Train R²: {train_r2_xgb:.4f}\")\n",
    "print(f\"Test R²: {test_r2_xgb:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'XGBoost (Tuned)',\n",
    "    'Train MAE': train_mae_xgb,\n",
    "    'Test MAE': test_mae_xgb,\n",
    "    'Train RMSE': train_rmse_xgb,\n",
    "    'Test RMSE': test_rmse_xgb,\n",
    "    'Train R²': train_r2_xgb,\n",
    "    'Test R²': test_r2_xgb\n",
    "})\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.2 AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training AdaBoost Regressor...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Define parameter grid for AdaBoost\n",
    "param_grid_ada = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.5, 1.0],\n",
    "    'loss': ['linear', 'square', 'exponential']\n",
    "}\n",
    "\n",
    "# Initialize AdaBoost with DecisionTree base estimator\n",
    "ada_model = AdaBoostRegressor(\n",
    "    estimator=DecisionTreeRegressor(max_depth=5, random_state=42),\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Grid search\n",
    "grid_search_ada = GridSearchCV(\n",
    "    ada_model,\n",
    "    param_grid_ada,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train\n",
    "grid_search_ada.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_ada = grid_search_ada.best_estimator_\n",
    "print(f\"\\nBest parameters: {grid_search_ada.best_params_}\")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_ada = best_ada.predict(X_train)\n",
    "y_pred_test_ada = best_ada.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "train_mae_ada = mean_absolute_error(y_train, y_pred_train_ada)\n",
    "test_mae_ada = mean_absolute_error(y_test, y_pred_test_ada)\n",
    "train_rmse_ada = np.sqrt(mean_squared_error(y_train, y_pred_train_ada))\n",
    "test_rmse_ada = np.sqrt(mean_squared_error(y_test, y_pred_test_ada))\n",
    "train_r2_ada = r2_score(y_train, y_pred_train_ada)\n",
    "test_r2_ada = r2_score(y_test, y_pred_test_ada)\n",
    "\n",
    "print(f\"\\nTrain MAE: {train_mae_ada:.2f} days\")\n",
    "print(f\"Test MAE: {test_mae_ada:.2f} days\")\n",
    "print(f\"Train RMSE: {train_rmse_ada:.2f} days\")\n",
    "print(f\"Test RMSE: {test_rmse_ada:.2f} days\")\n",
    "print(f\"Train R²: {train_r2_ada:.4f}\")\n",
    "print(f\"Test R²: {test_r2_ada:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'AdaBoost',\n",
    "    'Train MAE': train_mae_ada,\n",
    "    'Test MAE': test_mae_ada,\n",
    "    'Train RMSE': train_rmse_ada,\n",
    "    'Test RMSE': test_rmse_ada,\n",
    "    'Train R²': train_r2_ada,\n",
    "    'Test R²': test_r2_ada\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Unidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Unidirectional LSTM...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Build LSTM model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(128, activation='relu', return_sequences=True, input_shape=(1, X_train_lstm.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "lstm_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train\n",
    "print(\"\\nTraining LSTM model...\")\n",
    "history_lstm = lstm_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_lstm = lstm_model.predict(X_train_lstm, verbose=0).flatten()\n",
    "y_pred_test_lstm = lstm_model.predict(X_test_lstm, verbose=0).flatten()\n",
    "\n",
    "# Evaluate\n",
    "train_mae_lstm = mean_absolute_error(y_train, y_pred_train_lstm)\n",
    "test_mae_lstm = mean_absolute_error(y_test, y_pred_test_lstm)\n",
    "train_rmse_lstm = np.sqrt(mean_squared_error(y_train, y_pred_train_lstm))\n",
    "test_rmse_lstm = np.sqrt(mean_squared_error(y_test, y_pred_test_lstm))\n",
    "train_r2_lstm = r2_score(y_train, y_pred_train_lstm)\n",
    "test_r2_lstm = r2_score(y_test, y_pred_test_lstm)\n",
    "\n",
    "print(f\"\\nTrain MAE: {train_mae_lstm:.2f} days\")\n",
    "print(f\"Test MAE: {test_mae_lstm:.2f} days\")\n",
    "print(f\"Train RMSE: {train_rmse_lstm:.2f} days\")\n",
    "print(f\"Test RMSE: {test_rmse_lstm:.2f} days\")\n",
    "print(f\"Train R²: {train_r2_lstm:.4f}\")\n",
    "print(f\"Test R²: {test_r2_lstm:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'LSTM (Unidirectional)',\n",
    "    'Train MAE': train_mae_lstm,\n",
    "    'Test MAE': test_mae_lstm,\n",
    "    'Train RMSE': train_rmse_lstm,\n",
    "    'Test RMSE': test_rmse_lstm,\n",
    "    'Train R²': train_r2_lstm,\n",
    "    'Test R²': test_r2_lstm\n",
    "})\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_lstm.history['loss'], label='Train Loss')\n",
    "plt.plot(history_lstm.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE Loss')\n",
    "plt.title('LSTM Training History - Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_lstm.history['mae'], label='Train MAE')\n",
    "plt.plot(history_lstm.history['val_mae'], label='Val MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('LSTM Training History - MAE')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Training Bidirectional LSTM...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Build Bidirectional LSTM model\n",
    "bilstm_model = Sequential([\n",
    "    Bidirectional(LSTM(128, activation='relu', return_sequences=True), input_shape=(1, X_train_lstm.shape[2])),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(64, activation='relu', return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    Bidirectional(LSTM(32, activation='relu')),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "bilstm_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "early_stopping_bi = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "reduce_lr_bi = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6)\n",
    "\n",
    "# Train\n",
    "print(\"\\nTraining Bidirectional LSTM model...\")\n",
    "history_bilstm = bilstm_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_bi, reduce_lr_bi],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_train_bilstm = bilstm_model.predict(X_train_lstm, verbose=0).flatten()\n",
    "y_pred_test_bilstm = bilstm_model.predict(X_test_lstm, verbose=0).flatten()\n",
    "\n",
    "# Evaluate\n",
    "train_mae_bilstm = mean_absolute_error(y_train, y_pred_train_bilstm)\n",
    "test_mae_bilstm = mean_absolute_error(y_test, y_pred_test_bilstm)\n",
    "train_rmse_bilstm = np.sqrt(mean_squared_error(y_train, y_pred_train_bilstm))\n",
    "test_rmse_bilstm = np.sqrt(mean_squared_error(y_test, y_pred_test_bilstm))\n",
    "train_r2_bilstm = r2_score(y_train, y_pred_train_bilstm)\n",
    "test_r2_bilstm = r2_score(y_test, y_pred_test_bilstm)\n",
    "\n",
    "print(f\"\\nTrain MAE: {train_mae_bilstm:.2f} days\")\n",
    "print(f\"Test MAE: {test_mae_bilstm:.2f} days\")\n",
    "print(f\"Train RMSE: {train_rmse_bilstm:.2f} days\")\n",
    "print(f\"Test RMSE: {test_rmse_bilstm:.2f} days\")\n",
    "print(f\"Train R²: {train_r2_bilstm:.4f}\")\n",
    "print(f\"Test R²: {test_r2_bilstm:.4f}\")\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'Bidirectional LSTM',\n",
    "    'Train MAE': train_mae_bilstm,\n",
    "    'Test MAE': test_mae_bilstm,\n",
    "    'Train RMSE': train_rmse_bilstm,\n",
    "    'Test RMSE': test_rmse_bilstm,\n",
    "    'Train R²': train_r2_bilstm,\n",
    "    'Test R²': test_r2_bilstm\n",
    "})\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history_bilstm.history['loss'], label='Train Loss')\n",
    "plt.plot(history_bilstm.history['val_loss'], label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE Loss')\n",
    "plt.title('Bidirectional LSTM Training History - Loss')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history_bilstm.history['mae'], label='Train MAE')\n",
    "plt.plot(history_bilstm.history['val_mae'], label='Val MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.title('Bidirectional LSTM Training History - MAE')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 Model Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create results dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.sort_values('Test MAE')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL COMPARISON - ALL ADVANCED MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Identify best model\n",
    "best_model_name = results_df.iloc[0]['Model']\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"🏆 BEST MODEL: {best_model_name}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Test MAE: {results_df.iloc[0]['Test MAE']:.2f} days\")\n",
    "print(f\"Test RMSE: {results_df.iloc[0]['Test RMSE']:.2f} days\")\n",
    "print(f\"Test R²: {results_df.iloc[0]['Test R²']:.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization of model comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 1. Test MAE Comparison\n",
    "ax1 = axes[0, 0]\n",
    "bars = ax1.barh(results_df['Model'], results_df['Test MAE'], color='skyblue', edgecolor='navy')\n",
    "bars[0].set_color('gold')  # Highlight best model\n",
    "ax1.set_xlabel('Test MAE (days)')\n",
    "ax1.set_title('Test MAE Comparison\\n(Lower is Better)', fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 2. Test RMSE Comparison\n",
    "ax2 = axes[0, 1]\n",
    "bars = ax2.barh(results_df['Model'], results_df['Test RMSE'], color='lightcoral', edgecolor='darkred')\n",
    "bars[0].set_color('gold')\n",
    "ax2.set_xlabel('Test RMSE (days)')\n",
    "ax2.set_title('Test RMSE Comparison\\n(Lower is Better)', fontweight='bold')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Test R² Comparison\n",
    "ax3 = axes[0, 2]\n",
    "bars = ax3.barh(results_df['Model'], results_df['Test R²'], color='lightgreen', edgecolor='darkgreen')\n",
    "bars[0].set_color('gold')\n",
    "ax3.set_xlabel('Test R² Score')\n",
    "ax3.set_title('Test R² Comparison\\n(Higher is Better)', fontweight='bold')\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Train vs Test MAE\n",
    "ax4 = axes[1, 0]\n",
    "x_pos = np.arange(len(results_df))\n",
    "width = 0.35\n",
    "ax4.bar(x_pos - width/2, results_df['Train MAE'], width, label='Train MAE', alpha=0.8, color='steelblue')\n",
    "ax4.bar(x_pos + width/2, results_df['Test MAE'], width, label='Test MAE', alpha=0.8, color='orange')\n",
    "ax4.set_xlabel('Model')\n",
    "ax4.set_ylabel('MAE (days)')\n",
    "ax4.set_title('Train vs Test MAE', fontweight='bold')\n",
    "ax4.set_xticks(x_pos) \n",
    "ax4.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Train vs Test R²\n",
    "ax5 = axes[1, 1]\n",
    "ax5.bar(x_pos - width/2, results_df['Train R²'], width, label='Train R²', alpha=0.8, color='steelblue')\n",
    "ax5.bar(x_pos + width/2, results_df['Test R²'], width, label='Test R²', alpha=0.8, color='orange')\n",
    "ax5.set_xlabel('Model')\n",
    "ax5.set_ylabel('R² Score')\n",
    "ax5.set_title('Train vs Test R²', fontweight='bold')\n",
    "ax5.set_xticks(x_pos)\n",
    "ax5.set_xticklabels(results_df['Model'], rotation=45, ha='right')\n",
    "ax5.legend()\n",
    "ax5.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 6. Overfitting Analysis (Train MAE - Test MAE)\n",
    "ax6 = axes[1, 2]\n",
    "overfit_gap = results_df['Test MAE'] - results_df['Train MAE']\n",
    "colors = ['red' if x > 5 else 'green' for x in overfit_gap]\n",
    "ax6.barh(results_df['Model'], overfit_gap, color=colors, alpha=0.7)\n",
    "ax6.axvline(x=0, color='black', linestyle='--', linewidth=1)\n",
    "ax6.set_xlabel('Generalization Gap (days)')\n",
    "ax6.set_title('Overfitting Analysis\\n(Test MAE - Train MAE)', fontweight='bold')\n",
    "ax6.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. XGBoost Model Improvement - Reducing Overfitting\n",
    "\n",
    "**Problem Identified:**\n",
    "- Current XGBoost: Train MAE 3.50 vs Test MAE 8.56 (gap: 5.06 days)\n",
    "- Current XGBoost: Train R² 0.9354 vs Test R² 0.5384 (gap: 0.40)\n",
    "\n",
    "**Improvement Strategy:**\n",
    "1. Add regularization parameters (L1, L2, gamma)\n",
    "2. Reduce tree depth to prevent memorization\n",
    "3. Increase learning rate with fewer trees\n",
    "4. Add early stopping with validation set\n",
    "5. Reduce feature sampling per tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBOOST V2 - WITH ENHANCED REGULARIZATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define improved parameter grid with regularization\n",
    "param_grid_xgb_v2 = {\n",
    "    'n_estimators': [100, 200],              # Reduced from 300\n",
    "    'max_depth': [3, 4, 5],                  # Reduced from 10 (key change!)\n",
    "    'learning_rate': [0.05, 0.1, 0.15],      # Increased from 0.01\n",
    "    'subsample': [0.6, 0.7, 0.8],            # More aggressive sampling\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8],     # Feature sampling per tree\n",
    "    'min_child_weight': [3, 5, 7],           # Minimum samples per leaf\n",
    "    'gamma': [0, 0.1, 0.5],                  # Minimum loss reduction\n",
    "    'reg_alpha': [0, 0.01, 0.1],             # L1 regularization\n",
    "    'reg_lambda': [1.0, 5.0, 10.0]           # L2 regularization\n",
    "}\n",
    "\n",
    "print(f\"Grid search space: {np.prod([len(v) for v in param_grid_xgb_v2.values()]):,} combinations\")\n",
    "print(f\"This will take longer but should significantly reduce overfitting...\\n\")\n",
    "\n",
    "# Initialize XGBoost with base regularization\n",
    "xgb_model_v2 = xgb.XGBRegressor(\n",
    "    random_state=42, \n",
    "    n_jobs=-1,\n",
    "    objective='reg:squarederror'\n",
    ")\n",
    "\n",
    "# Grid search with cross-validation\n",
    "grid_search_xgb_v2 = GridSearchCV(\n",
    "    xgb_model_v2, \n",
    "    param_grid_xgb_v2, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_absolute_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Train\n",
    "print(\"Starting grid search (this may take 10-15 minutes)...\")\n",
    "grid_search_xgb_v2.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_xgb_v2 = grid_search_xgb_v2.best_estimator_\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Best Parameters Found:\")\n",
    "print(f\"{'='*60}\")\n",
    "for param, value in grid_search_xgb_v2.best_params_.items():\n",
    "    print(f\"  {param:20s}: {value}\")\n",
    "print(f\"\\nBest CV Score: {-grid_search_xgb_v2.best_score_:.2f} days MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate XGBoost V2\n",
    "y_pred_train_xgb_v2 = best_xgb_v2.predict(X_train)\n",
    "y_pred_test_xgb_v2 = best_xgb_v2.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae_xgb_v2 = mean_absolute_error(y_train, y_pred_train_xgb_v2)\n",
    "test_mae_xgb_v2 = mean_absolute_error(y_test, y_pred_test_xgb_v2)\n",
    "train_rmse_xgb_v2 = np.sqrt(mean_squared_error(y_train, y_pred_train_xgb_v2))\n",
    "test_rmse_xgb_v2 = np.sqrt(mean_squared_error(y_test, y_pred_test_xgb_v2))\n",
    "train_r2_xgb_v2 = r2_score(y_train, y_pred_train_xgb_v2)\n",
    "test_r2_xgb_v2 = r2_score(y_test, y_pred_test_xgb_v2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"XGBOOST V2 PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train MAE:  {train_mae_xgb_v2:.2f} days\")\n",
    "print(f\"Test MAE:   {test_mae_xgb_v2:.2f} days\")\n",
    "print(f\"MAE Gap:    {abs(test_mae_xgb_v2 - train_mae_xgb_v2):.2f} days\\n\")\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse_xgb_v2:.2f} days\")\n",
    "print(f\"Test RMSE:  {test_rmse_xgb_v2:.2f} days\\n\")\n",
    "\n",
    "print(f\"Train R²:   {train_r2_xgb_v2:.4f}\")\n",
    "print(f\"Test R²:    {test_r2_xgb_v2:.4f}\")\n",
    "print(f\"R² Gap:     {abs(train_r2_xgb_v2 - test_r2_xgb_v2):.4f}\")\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'XGBoost V2 (Regularized)',\n",
    "    'Train MAE': train_mae_xgb_v2,\n",
    "    'Test MAE': test_mae_xgb_v2,\n",
    "    'Train RMSE': train_rmse_xgb_v2,\n",
    "    'Test RMSE': test_rmse_xgb_v2,\n",
    "    'Train R²': train_r2_xgb_v2,\n",
    "    'Test R²': test_r2_xgb_v2\n",
    "})\n",
    "\n",
    "# Compare with original XGBoost\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: V1 vs V2\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'V1 (Original)':<20} {'V2 (Regularized)':<20} {'Improvement':<15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Train MAE':<20} {train_mae_xgb:.2f} days{'':<10} {train_mae_xgb_v2:.2f} days{'':<10} {train_mae_xgb_v2 - train_mae_xgb:+.2f} days\")\n",
    "print(f\"{'Test MAE':<20} {test_mae_xgb:.2f} days{'':<10} {test_mae_xgb_v2:.2f} days{'':<10} {test_mae_xgb_v2 - test_mae_xgb:+.2f} days\")\n",
    "print(f\"{'MAE Gap':<20} {abs(test_mae_xgb - train_mae_xgb):.2f} days{'':<10} {abs(test_mae_xgb_v2 - train_mae_xgb_v2):.2f} days{'':<10} {abs(test_mae_xgb_v2 - train_mae_xgb_v2) - abs(test_mae_xgb - train_mae_xgb):+.2f} days\")\n",
    "print(f\"{'Test R²':<20} {test_r2_xgb:.4f}{'':<14} {test_r2_xgb_v2:.4f}{'':<14} {test_r2_xgb_v2 - test_r2_xgb:+.4f}\")\n",
    "print(f\"{'R² Gap':<20} {abs(train_r2_xgb - test_r2_xgb):.4f}{'':<14} {abs(train_r2_xgb_v2 - test_r2_xgb_v2):.4f}{'':<14} {abs(train_r2_xgb_v2 - test_r2_xgb_v2) - abs(train_r2_xgb - test_r2_xgb):+.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.3 Model Ensemble - Combining XGBoost V2 with LSTMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ENSEMBLE MODEL - Weighted Average of Best Models\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Strategy: Combine models with different strengths\n",
    "# - XGBoost V2: Best test MAE, but may still overfit slightly\n",
    "# - Bidirectional LSTM: Better generalization (smaller train-test gap)\n",
    "# - Unidirectional LSTM: Similar to BiLSTM\n",
    "\n",
    "# Weighted ensemble (you can adjust these weights)\n",
    "weights = {\n",
    "    'xgb_v2': 0.50,      # Highest weight to best model\n",
    "    'bilstm': 0.30,      # Good generalization\n",
    "    'lstm': 0.20         # Additional diversity\n",
    "}\n",
    "\n",
    "print(f\"Ensemble weights:\")\n",
    "print(f\"  XGBoost V2:         {weights['xgb_v2']:.0%}\")\n",
    "print(f\"  Bidirectional LSTM: {weights['bilstm']:.0%}\")\n",
    "print(f\"  Unidirectional LSTM: {weights['lstm']:.0%}\")\n",
    "print(f\"  Total:              {sum(weights.values()):.0%}\\n\")\n",
    "\n",
    "# Create ensemble predictions\n",
    "y_pred_train_ensemble = (\n",
    "    weights['xgb_v2'] * y_pred_train_xgb_v2 +\n",
    "    weights['bilstm'] * y_pred_train_bilstm +\n",
    "    weights['lstm'] * y_pred_train_lstm\n",
    ")\n",
    "\n",
    "y_pred_test_ensemble = (\n",
    "    weights['xgb_v2'] * y_pred_test_xgb_v2 +\n",
    "    weights['bilstm'] * y_pred_test_bilstm +\n",
    "    weights['lstm'] * y_pred_test_lstm\n",
    ")\n",
    "\n",
    "# Evaluate ensemble\n",
    "train_mae_ensemble = mean_absolute_error(y_train, y_pred_train_ensemble)\n",
    "test_mae_ensemble = mean_absolute_error(y_test, y_pred_test_ensemble)\n",
    "train_rmse_ensemble = np.sqrt(mean_squared_error(y_train, y_pred_train_ensemble))\n",
    "test_rmse_ensemble = np.sqrt(mean_squared_error(y_test, y_pred_test_ensemble))\n",
    "train_r2_ensemble = r2_score(y_train, y_pred_train_ensemble)\n",
    "test_r2_ensemble = r2_score(y_test, y_pred_test_ensemble)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENSEMBLE PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train MAE:  {train_mae_ensemble:.2f} days\")\n",
    "print(f\"Test MAE:   {test_mae_ensemble:.2f} days\")\n",
    "print(f\"MAE Gap:    {abs(test_mae_ensemble - train_mae_ensemble):.2f} days\\n\")\n",
    "\n",
    "print(f\"Train RMSE: {train_rmse_ensemble:.2f} days\")\n",
    "print(f\"Test RMSE:  {test_rmse_ensemble:.2f} days\\n\")\n",
    "\n",
    "print(f\"Train R²:   {train_r2_ensemble:.4f}\")\n",
    "print(f\"Test R²:    {test_r2_ensemble:.4f}\")\n",
    "print(f\"R² Gap:     {abs(train_r2_ensemble - test_r2_ensemble):.4f}\")\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'Ensemble (50% XGB V2 + 30% BiLSTM + 20% LSTM)',\n",
    "    'Train MAE': train_mae_ensemble,\n",
    "    'Test MAE': test_mae_ensemble,\n",
    "    'Train RMSE': train_rmse_ensemble,\n",
    "    'Test RMSE': test_rmse_ensemble,\n",
    "    'Train R²': train_r2_ensemble,\n",
    "    'Test R²': test_r2_ensemble\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.4 Final Model Comparison - All Models Including Improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results dataframe\n",
    "results_df_final = pd.DataFrame(results)\n",
    "results_df_final = results_df_final.sort_values('Test MAE')\n",
    "\n",
    "# Add generalization gap column\n",
    "results_df_final['MAE Gap'] = results_df_final['Test MAE'] - results_df_final['Train MAE']\n",
    "results_df_final['R² Gap'] = results_df_final['Train R²'] - results_df_final['Test R²']\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"FINAL MODEL COMPARISON - ALL MODELS (SORTED BY TEST MAE)\")\n",
    "print(\"=\"*100)\n",
    "print(results_df_final.to_string(index=False))\n",
    "\n",
    "# Identify best overall model\n",
    "best_model_final = results_df_final.iloc[0]['Model']\n",
    "print(f\"\\n{'='*100}\")\n",
    "print(f\"🏆 BEST MODEL: {best_model_final}\")\n",
    "print(f\"{'='*100}\")\n",
    "print(f\"Test MAE:       {results_df_final.iloc[0]['Test MAE']:.2f} days\")\n",
    "print(f\"Test RMSE:      {results_df_final.iloc[0]['Test RMSE']:.2f} days\")\n",
    "print(f\"Test R²:        {results_df_final.iloc[0]['Test R²']:.4f}\")\n",
    "print(f\"MAE Gap:        {results_df_final.iloc[0]['MAE Gap']:.2f} days (Train vs Test)\")\n",
    "print(f\"R² Gap:         {results_df_final.iloc[0]['R² Gap']:.4f} (Train vs Test)\")\n",
    "print(f\"{'='*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive visualization comparing all models\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "\n",
    "# 1. Test MAE Comparison\n",
    "ax1 = axes[0, 0]\n",
    "colors_mae = ['gold' if i == 0 else 'skyblue' for i in range(len(results_df_final))]\n",
    "bars = ax1.barh(results_df_final['Model'], results_df_final['Test MAE'], color=colors_mae, edgecolor='navy')\n",
    "ax1.set_xlabel('Test MAE (days)', fontsize=11)\n",
    "ax1.set_title('Test MAE Comparison\\n(Lower is Better)', fontweight='bold', fontsize=12)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 2. Generalization Gap (MAE)\n",
    "ax2 = axes[0, 1]\n",
    "colors_gap = ['green' if x < 3 else ('orange' if x < 5 else 'red') for x in results_df_final['MAE Gap']]\n",
    "bars = ax2.barh(results_df_final['Model'], results_df_final['MAE Gap'], color=colors_gap, alpha=0.7)\n",
    "ax2.axvline(x=3, color='orange', linestyle='--', linewidth=1, alpha=0.5, label='Acceptable (<3 days)')\n",
    "ax2.axvline(x=5, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Poor (>5 days)')\n",
    "ax2.set_xlabel('MAE Gap (Test - Train)', fontsize=11)\n",
    "ax2.set_title('Generalization Gap - MAE\\n(Lower is Better)', fontweight='bold', fontsize=12)\n",
    "ax2.legend(fontsize=9)\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 3. Test R² Comparison\n",
    "ax3 = axes[0, 2]\n",
    "colors_r2 = ['gold' if i == 0 else 'lightgreen' for i in range(len(results_df_final))]\n",
    "bars = ax3.barh(results_df_final['Model'], results_df_final['Test R²'], color=colors_r2, edgecolor='darkgreen')\n",
    "ax3.set_xlabel('Test R² Score', fontsize=11)\n",
    "ax3.set_title('Test R² Comparison\\n(Higher is Better)', fontweight='bold', fontsize=12)\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 4. Train vs Test MAE\n",
    "ax4 = axes[1, 0]\n",
    "x_pos = np.arange(len(results_df_final))\n",
    "width = 0.35\n",
    "ax4.bar(x_pos - width/2, results_df_final['Train MAE'], width, label='Train MAE', alpha=0.8, color='steelblue')\n",
    "ax4.bar(x_pos + width/2, results_df_final['Test MAE'], width, label='Test MAE', alpha=0.8, color='orange')\n",
    "ax4.set_xlabel('Model', fontsize=11)\n",
    "ax4.set_ylabel('MAE (days)', fontsize=11)\n",
    "ax4.set_title('Train vs Test MAE', fontweight='bold', fontsize=12)\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(results_df_final['Model'], rotation=45, ha='right', fontsize=9)\n",
    "ax4.legend()\n",
    "ax4.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 5. Generalization Gap (R²)\n",
    "ax5 = axes[1, 1]\n",
    "colors_gap_r2 = ['green' if x < 0.15 else ('orange' if x < 0.3 else 'red') for x in results_df_final['R² Gap']]\n",
    "bars = ax5.barh(results_df_final['Model'], results_df_final['R² Gap'], color=colors_gap_r2, alpha=0.7)\n",
    "ax5.axvline(x=0.15, color='orange', linestyle='--', linewidth=1, alpha=0.5, label='Acceptable (<0.15)')\n",
    "ax5.axvline(x=0.3, color='red', linestyle='--', linewidth=1, alpha=0.5, label='Poor (>0.3)')\n",
    "ax5.set_xlabel('R² Gap (Train - Test)', fontsize=11)\n",
    "ax5.set_title('Generalization Gap - R²\\n(Lower is Better)', fontweight='bold', fontsize=12)\n",
    "ax5.legend(fontsize=9)\n",
    "ax5.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# 6. Overall Performance Score\n",
    "ax6 = axes[1, 2]\n",
    "# Composite score: Lower is better (normalized MAE + normalized Gap)\n",
    "mae_norm = (results_df_final['Test MAE'] - results_df_final['Test MAE'].min()) / (results_df_final['Test MAE'].max() - results_df_final['Test MAE'].min())\n",
    "gap_norm = (results_df_final['MAE Gap'] - results_df_final['MAE Gap'].min()) / (results_df_final['MAE Gap'].max() - results_df_final['MAE Gap'].min())\n",
    "composite_score = (mae_norm + gap_norm) / 2\n",
    "results_df_final['Composite Score'] = composite_score\n",
    "\n",
    "colors_comp = ['gold' if i == composite_score.idxmin() else 'lightblue' for i in range(len(results_df_final))]\n",
    "bars = ax6.barh(results_df_final['Model'], 1 - composite_score, color=colors_comp, edgecolor='navy')\n",
    "ax6.set_xlabel('Overall Score (Higher is Better)', fontsize=11)\n",
    "ax6.set_title('Overall Performance\\n(Test MAE + Generalization)', fontweight='bold', fontsize=12)\n",
    "ax6.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\"*100)\n",
    "print(\"✓ Green bars in generalization gap charts = Good generalization\")\n",
    "print(\"✓ Orange bars = Acceptable overfitting\")\n",
    "print(\"✓ Red bars = Significant overfitting issue\")\n",
    "print(\"✓ Overall score balances test performance and generalization\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Ensemble Weight Optimization\n",
    "\n",
    "**Current ensemble weights:**\n",
    "- XGBoost V2: 50%\n",
    "- Bidirectional LSTM: 30%\n",
    "- Unidirectional LSTM: 20%\n",
    "\n",
    "**Objective:** Find the optimal weight combination to minimize test MAE while maintaining good generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"ENSEMBLE WEIGHT OPTIMIZATION - ALL 4 MODELS\")\n",
    "print(\"=\"*80)\n",
    "print(\"Models: XGBoost (Tuned), Bidirectional LSTM, LSTM (Unidirectional), AdaBoost\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Generate all possible weight combinations (in increments of 0.05)\n",
    "weight_combinations = []\n",
    "for w_xgb in np.arange(0.0, 1.05, 0.05):\n",
    "    for w_bilstm in np.arange(0.0, 1.05, 0.05):\n",
    "        for w_lstm in np.arange(0.0, 1.05, 0.05):\n",
    "            for w_ada in np.arange(0.0, 1.05, 0.05):\n",
    "                # Ensure weights sum to 1 (with small tolerance for floating point)\n",
    "                if abs(w_xgb + w_bilstm + w_lstm + w_ada - 1.0) < 0.01:\n",
    "                    weight_combinations.append({\n",
    "                        'w_xgb': round(w_xgb, 2),\n",
    "                        'w_bilstm': round(w_bilstm, 2),\n",
    "                        'w_lstm': round(w_lstm, 2),\n",
    "                        'w_ada': round(w_ada, 2)\n",
    "                    })\n",
    "\n",
    "print(f\"Total weight combinations to test: {len(weight_combinations):,}\")\n",
    "print(f\"Testing all combinations...\\n\")\n",
    "\n",
    "# Evaluate all combinations\n",
    "ensemble_results = []\n",
    "\n",
    "for weights in weight_combinations:\n",
    "    # Create ensemble predictions\n",
    "    y_pred_train_ens = (\n",
    "        weights['w_xgb'] * y_pred_train_xgb_v2 +\n",
    "        weights['w_bilstm'] * y_pred_train_bilstm +\n",
    "        weights['w_lstm'] * y_pred_train_lstm +\n",
    "        weights['w_ada'] * y_pred_train_ada\n",
    "    )\n",
    "    \n",
    "    y_pred_test_ens = (\n",
    "        weights['w_xgb'] * y_pred_test_xgb_v2 +\n",
    "        weights['w_bilstm'] * y_pred_test_bilstm +\n",
    "        weights['w_lstm'] * y_pred_test_lstm +\n",
    "        weights['w_ada'] * y_pred_test_ada\n",
    "    )\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train_ens)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test_ens)\n",
    "    train_r2 = r2_score(y_train, y_pred_train_ens)\n",
    "    test_r2 = r2_score(y_test, y_pred_test_ens)\n",
    "    mae_gap = test_mae - train_mae\n",
    "    r2_gap = train_r2 - test_r2\n",
    "    \n",
    "    ensemble_results.append({\n",
    "        'XGB_V2': weights['w_xgb'],\n",
    "        'BiLSTM': weights['w_bilstm'],\n",
    "        'LSTM': weights['w_lstm'],\n",
    "        'AdaBoost': weights['w_ada'],\n",
    "        'Train_MAE': train_mae,\n",
    "        'Test_MAE': test_mae,\n",
    "        'MAE_Gap': mae_gap,\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2,\n",
    "        'R2_Gap': r2_gap\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "ensemble_df = pd.DataFrame(ensemble_results)\n",
    "\n",
    "print(f\"✓ Evaluated {len(ensemble_df):,} weight combinations\")\n",
    "print(f\"\\nOptimization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find top 10 combinations by different criteria\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 ENSEMBLES BY TEST MAE (Best Accuracy)\")\n",
    "print(\"=\"*80)\n",
    "top_by_mae = ensemble_df.nsmallest(10, 'Test_MAE')[['XGB_V2', 'BiLSTM', 'LSTM', 'AdaBoost', 'Test_MAE', 'MAE_Gap', 'Test_R2', 'R2_Gap']]\n",
    "print(top_by_mae.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 ENSEMBLES BY MAE GAP (Best Generalization)\")\n",
    "print(\"=\"*80)\n",
    "top_by_gap = ensemble_df.nsmallest(10, 'MAE_Gap')[['XGB_V2', 'BiLSTM', 'LSTM', 'AdaBoost', 'Test_MAE', 'MAE_Gap', 'Test_R2', 'R2_Gap']]\n",
    "print(top_by_gap.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 ENSEMBLES BY TEST R² (Best Explanatory Power)\")\n",
    "print(\"=\"*80)\n",
    "top_by_r2 = ensemble_df.nlargest(10, 'Test_R2')[['XGB_V2', 'BiLSTM', 'LSTM', 'AdaBoost', 'Test_MAE', 'MAE_Gap', 'Test_R2', 'R2_Gap']]\n",
    "print(top_by_r2.to_string(index=False))\n",
    "\n",
    "# Composite score: Balance accuracy and generalization\n",
    "# Lower test MAE is good, lower MAE Gap is good\n",
    "ensemble_df['Composite_Score'] = (\n",
    "    0.6 * (ensemble_df['Test_MAE'] - ensemble_df['Test_MAE'].min()) / (ensemble_df['Test_MAE'].max() - ensemble_df['Test_MAE'].min()) +\n",
    "    0.4 * (ensemble_df['MAE_Gap'] - ensemble_df['MAE_Gap'].min()) / (ensemble_df['MAE_Gap'].max() - ensemble_df['MAE_Gap'].min())\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 ENSEMBLES BY COMPOSITE SCORE (60% Accuracy + 40% Generalization)\")\n",
    "print(\"=\"*80)\n",
    "top_composite = ensemble_df.nsmallest(10, 'Composite_Score')[['XGB_V2', 'BiLSTM', 'LSTM', 'AdaBoost', 'Test_MAE', 'MAE_Gap', 'Test_R2', 'R2_Gap', 'Composite_Score']]\n",
    "print(top_composite.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best ensemble based on composite score\n",
    "best_ensemble = ensemble_df.nsmallest(1, 'Composite_Score').iloc[0]\n",
    "\n",
    "print()\n",
    "print('='*100)\n",
    "print('OPTIMAL ENSEMBLE WEIGHTS FOUND!')\n",
    "print('='*100)\n",
    "print()\n",
    "print('Best Weight Combination:')\n",
    "print(f\"  XGBoost V2:          {best_ensemble['XGB_V2']:.0%}\")\n",
    "print(f\"  Bidirectional LSTM:  {best_ensemble['BiLSTM']:.0%}\")\n",
    "print(f\"  Unidirectional LSTM: {best_ensemble['LSTM']:.0%}\")\n",
    "print(f\"  AdaBoost:            {best_ensemble['AdaBoost']:.0%}\")\n",
    "print()\n",
    "print('Performance Metrics:')\n",
    "print(f\"  Test MAE:     {best_ensemble['Test_MAE']:.2f} days\")\n",
    "print(f\"  MAE Gap:      {best_ensemble['MAE_Gap']:.2f} days\")\n",
    "print(f\"  Test R²:      {best_ensemble['Test_R2']:.4f}\")\n",
    "print(f\"  R² Gap:       {best_ensemble['R2_Gap']:.4f}\")\n",
    "print(f\"  Composite Score: {best_ensemble['Composite_Score']:.4f}\")\n",
    "print()\n",
    "print('='*100)\n",
    "print('COMPARISON: Original Ensemble vs Optimized Ensemble')\n",
    "print('='*100)\n",
    "\n",
    "# Calculate original ensemble metrics (40% XGB V2 + 30% BiLSTM + 20% LSTM + 10% AdaBoost)\n",
    "# This is a reasonable starting point before optimization\n",
    "original_ensemble_pred_train = 0.40 * y_pred_train_xgb_v2 + 0.30 * y_pred_train_bilstm + 0.20 * y_pred_train_lstm + 0.10 * y_pred_train_ada\n",
    "original_ensemble_pred_test = 0.40 * y_pred_test_xgb_v2 + 0.30 * y_pred_test_bilstm + 0.20 * y_pred_test_lstm + 0.10 * y_pred_test_ada\n",
    "\n",
    "original_train_mae = mean_absolute_error(y_train, original_ensemble_pred_train)\n",
    "original_test_mae = mean_absolute_error(y_test, original_ensemble_pred_test)\n",
    "original_mae_gap = original_test_mae - original_train_mae\n",
    "original_test_r2 = r2_score(y_test, original_ensemble_pred_test)\n",
    "\n",
    "# Create formatted strings\n",
    "orig_weights = '40% / 30% / 20% / 10%'\n",
    "opt_weights = f\"{best_ensemble['XGB_V2']:.0%} / {best_ensemble['BiLSTM']:.0%} / {best_ensemble['LSTM']:.0%} / {best_ensemble['AdaBoost']:.0%}\"\n",
    "\n",
    "print(f\"{'Metric':<20} {'Original (40/30/20/10)':<25} {'Optimized':<25} {'Improvement':<15}\")\n",
    "print('-' * 100)\n",
    "print(f\"{'Weights':<20} {orig_weights:<25} {opt_weights:<25}\")\n",
    "print(f\"{'Test MAE':<20} {original_test_mae:<25.2f} {best_ensemble['Test_MAE']:<25.2f} {best_ensemble['Test_MAE'] - original_test_mae:+.2f} days\")\n",
    "print(f\"{'MAE Gap':<20} {original_mae_gap:<25.2f} {best_ensemble['MAE_Gap']:<25.2f} {best_ensemble['MAE_Gap'] - original_mae_gap:+.2f} days\")\n",
    "print(f\"{'Test R²':<20} {original_test_r2:<25.4f} {best_ensemble['Test_R2']:<25.4f} {best_ensemble['Test_R2'] - original_test_r2:+.4f}\")\n",
    "print('='*100)\n",
    "\n",
    "# Store best ensemble results\n",
    "opt_model_name = f\"Ensemble OPTIMIZED ({best_ensemble['XGB_V2']:.0%} XGB V2 + {best_ensemble['BiLSTM']:.0%} BiLSTM + {best_ensemble['LSTM']:.0%} LSTM + {best_ensemble['AdaBoost']:.0%} AdaBoost)\"\n",
    "\n",
    "# Calculate predictions for best ensemble\n",
    "y_pred_train_opt = (\n",
    "    best_ensemble['XGB_V2'] * y_pred_train_xgb_v2 + \n",
    "    best_ensemble['BiLSTM'] * y_pred_train_bilstm + \n",
    "    best_ensemble['LSTM'] * y_pred_train_lstm +\n",
    "    best_ensemble['AdaBoost'] * y_pred_train_ada\n",
    ")\n",
    "\n",
    "y_pred_test_opt = (\n",
    "    best_ensemble['XGB_V2'] * y_pred_test_xgb_v2 + \n",
    "    best_ensemble['BiLSTM'] * y_pred_test_bilstm + \n",
    "    best_ensemble['LSTM'] * y_pred_test_lstm +\n",
    "    best_ensemble['AdaBoost'] * y_pred_test_ada\n",
    ")\n",
    "\n",
    "results.append({\n",
    "    'Model': opt_model_name,\n",
    "    'Train MAE': best_ensemble['Train_MAE'],\n",
    "    'Test MAE': best_ensemble['Test_MAE'],\n",
    "    'Train RMSE': np.sqrt(mean_squared_error(y_train, y_pred_train_opt)),\n",
    "    'Test RMSE': np.sqrt(mean_squared_error(y_test, y_pred_test_opt)),\n",
    "    'Train R²': best_ensemble['Train_R2'],\n",
    "    'Test R²': best_ensemble['Test_R2']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize optimization results\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Test MAE vs MAE Gap scatter plot\n",
    "ax1 = axes[0, 0]\n",
    "scatter = ax1.scatter(ensemble_df['Test_MAE'], ensemble_df['MAE_Gap'], \n",
    "                     c=ensemble_df['Test_R2'], cmap='RdYlGn', alpha=0.6, s=30)\n",
    "ax1.scatter(best_ensemble['Test_MAE'], best_ensemble['MAE_Gap'], \n",
    "           color='red', s=200, marker='*', edgecolors='black', linewidths=2, \n",
    "           label='Optimal', zorder=5)\n",
    "ax1.set_xlabel('Test MAE (days)', fontsize=11)\n",
    "ax1.set_ylabel('MAE Gap (days)', fontsize=11)\n",
    "ax1.set_title('Ensemble Performance Space\\n(Star = Optimal)', fontweight='bold', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "cbar1 = plt.colorbar(scatter, ax=ax1)\n",
    "cbar1.set_label('Test R²', fontsize=10)\n",
    "\n",
    "# 2. Weight distribution for top 20 ensembles\n",
    "ax2 = axes[0, 1]\n",
    "top_20 = ensemble_df.nsmallest(20, 'Composite_Score')\n",
    "x_pos = np.arange(len(top_20))\n",
    "width = 0.25\n",
    "\n",
    "ax2.bar(x_pos - width, top_20['XGB_V2'], width, label='XGBoost V2', alpha=0.8, color='steelblue')\n",
    "ax2.bar(x_pos, top_20['BiLSTM'], width, label='BiLSTM', alpha=0.8, color='orange')\n",
    "ax2.bar(x_pos + width, top_20['LSTM'], width, label='LSTM', alpha=0.8, color='green')\n",
    "ax2.set_xlabel('Rank (1 = Best)', fontsize=11)\n",
    "ax2.set_ylabel('Weight', fontsize=11)\n",
    "ax2.set_title('Weight Distribution for Top 20 Ensembles', fontweight='bold', fontsize=12)\n",
    "ax2.set_xticks(x_pos[::2])\n",
    "ax2.set_xticklabels(range(1, 21)[::2])\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Heatmap: XGBoost vs BiLSTM weight (averaging over LSTM)\n",
    "ax3 = axes[1, 0]\n",
    "pivot_data = ensemble_df.groupby(['XGB_V2', 'BiLSTM'])['Test_MAE'].mean().reset_index()\n",
    "pivot_table = pivot_data.pivot(index='BiLSTM', columns='XGB_V2', values='Test_MAE')\n",
    "im = ax3.imshow(pivot_table, cmap='RdYlGn_r', aspect='auto', origin='lower')\n",
    "ax3.set_xlabel('XGBoost V2 Weight', fontsize=11)\n",
    "ax3.set_ylabel('BiLSTM Weight', fontsize=11)\n",
    "ax3.set_title('Test MAE Heatmap\\n(Averaged over LSTM weights)', fontweight='bold', fontsize=12)\n",
    "ax3.set_xticks(range(0, len(pivot_table.columns), 4))\n",
    "ax3.set_xticklabels([f'{x:.1f}' for x in pivot_table.columns[::4]], fontsize=9)\n",
    "ax3.set_yticks(range(0, len(pivot_table.index), 4))\n",
    "ax3.set_yticklabels([f'{y:.1f}' for y in pivot_table.index[::4]], fontsize=9)\n",
    "cbar3 = plt.colorbar(im, ax=ax3)\n",
    "cbar3.set_label('Test MAE (days)', fontsize=10)\n",
    "\n",
    "# 4. Top 10 ensembles comparison\n",
    "ax4 = axes[1, 1]\n",
    "top_10_display = ensemble_df.nsmallest(10, 'Composite_Score')\n",
    "labels = [f\"{row['XGB_V2']:.0%}/{row['BiLSTM']:.0%}/{row['LSTM']:.0%}\" \n",
    "          for _, row in top_10_display.iterrows()]\n",
    "y_pos = np.arange(len(labels))\n",
    "\n",
    "colors_ranking = ['gold' if i == 0 else 'lightblue' for i in range(len(labels))]\n",
    "bars = ax4.barh(y_pos, top_10_display['Test_MAE'], color=colors_ranking, edgecolor='navy', alpha=0.7)\n",
    "ax4.set_yticks(y_pos)\n",
    "ax4.set_yticklabels(labels, fontsize=9)\n",
    "ax4.set_xlabel('Test MAE (days)', fontsize=11)\n",
    "ax4.set_ylabel('Ensemble Weights (XGB/BiLSTM/LSTM)', fontsize=11)\n",
    "ax4.set_title('Top 10 Ensemble Configurations', fontweight='bold', fontsize=12)\n",
    "ax4.invert_yaxis()\n",
    "ax4.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add values on bars\n",
    "for i, (bar, val) in enumerate(zip(bars, top_10_display['Test_MAE'])):\n",
    "    gap_val = top_10_display.iloc[i]['MAE_Gap']\n",
    "    ax4.text(val + 0.1, bar.get_y() + bar.get_height()/2, \n",
    "            f'{val:.2f} (gap: {gap_val:.2f})', \n",
    "            va='center', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"VISUALIZATION INSIGHTS:\")\n",
    "print(\"=\"*80)\n",
    "print(\"✓ Top-left plot: Red star shows optimal balance of accuracy vs generalization\")\n",
    "print(\"✓ Top-right plot: Weight distribution shows diversity in top performers\")\n",
    "print(\"✓ Bottom-left plot: Heatmap reveals optimal weight regions (green = better)\")\n",
    "print(\"✓ Bottom-right plot: Top 10 configurations with their test MAE and gaps\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. LSTM V2 - Architecture Optimization\n",
    "\n",
    "**Insight from ensemble optimization:** LSTM contributes 60% to optimal ensemble, suggesting it's valuable but could be improved.\n",
    "\n",
    "**Improvement Strategy:**\n",
    "1. Increase model depth (more LSTM layers)\n",
    "2. Add more units per layer\n",
    "3. Stronger regularization (higher dropout)\n",
    "4. Better learning rate scheduling\n",
    "5. Longer training with early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LSTM V2 - IMPROVED ARCHITECTURE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Build improved LSTM model with deeper architecture\n",
    "lstm_v2_model = Sequential([\n",
    "    # First LSTM layer - larger with return sequences\n",
    "    LSTM(256, activation='relu', return_sequences=True, input_shape=(1, X_train_lstm.shape[2])),\n",
    "    Dropout(0.3),  # Increased from 0.2\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    LSTM(128, activation='relu', return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Third LSTM layer\n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Fourth LSTM layer\n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    \n",
    "    # Dense layers\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile with lower learning rate for better convergence\n",
    "lstm_v2_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.0005),  # Reduced from 0.001\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Enhanced callbacks\n",
    "early_stopping_v2 = EarlyStopping(\n",
    "    monitor='val_loss', \n",
    "    patience=20,  # Increased from 15\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_v2 = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.5, \n",
    "    patience=7,  # Increased from 5\n",
    "    min_lr=1e-7,  # Lower minimum\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nModel Architecture:\")\n",
    "lstm_v2_model.summary()\n",
    "\n",
    "print(\"\\nStarting training with improved architecture...\")\n",
    "print(\"This may take 5-10 minutes...\")\n",
    "\n",
    "# Train with more epochs\n",
    "history_lstm_v2 = lstm_v2_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=150,  # Increased from 100\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_v2, reduce_lr_v2],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✓ LSTM V2 training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate LSTM V2\n",
    "y_pred_train_lstm_v2 = lstm_v2_model.predict(X_train_lstm, verbose=0).flatten()\n",
    "y_pred_test_lstm_v2 = lstm_v2_model.predict(X_test_lstm, verbose=0).flatten()\n",
    "\n",
    "# Calculate metrics\n",
    "train_mae_lstm_v2 = mean_absolute_error(y_train, y_pred_train_lstm_v2)\n",
    "test_mae_lstm_v2 = mean_absolute_error(y_test, y_pred_test_lstm_v2)\n",
    "train_rmse_lstm_v2 = np.sqrt(mean_squared_error(y_train, y_pred_train_lstm_v2))\n",
    "test_rmse_lstm_v2 = np.sqrt(mean_squared_error(y_test, y_pred_test_lstm_v2))\n",
    "train_r2_lstm_v2 = r2_score(y_train, y_pred_train_lstm_v2)\n",
    "test_r2_lstm_v2 = r2_score(y_test, y_pred_test_lstm_v2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LSTM V2 PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Train MAE:  {train_mae_lstm_v2:.2f} days\")\n",
    "print(f\"Test MAE:   {test_mae_lstm_v2:.2f} days\")\n",
    "print(f\"MAE Gap:    {abs(test_mae_lstm_v2 - train_mae_lstm_v2):.2f} days\")\n",
    "print()\n",
    "print(f\"Train RMSE: {train_rmse_lstm_v2:.2f} days\")\n",
    "print(f\"Test RMSE:  {test_rmse_lstm_v2:.2f} days\")\n",
    "print()\n",
    "print(f\"Train R²:   {train_r2_lstm_v2:.4f}\")\n",
    "print(f\"Test R²:    {test_r2_lstm_v2:.4f}\")\n",
    "print(f\"R² Gap:     {abs(train_r2_lstm_v2 - test_r2_lstm_v2):.4f}\")\n",
    "\n",
    "# Compare with original LSTM\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: LSTM V1 vs LSTM V2\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'V1 (Original)':<20} {'V2 (Improved)':<20} {'Change':<15}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Train MAE':<20} {train_mae_lstm:.2f} days{'':<11} {train_mae_lstm_v2:.2f} days{'':<11} {train_mae_lstm_v2 - train_mae_lstm:+.2f} days\")\n",
    "print(f\"{'Test MAE':<20} {test_mae_lstm:.2f} days{'':<11} {test_mae_lstm_v2:.2f} days{'':<11} {test_mae_lstm_v2 - test_mae_lstm:+.2f} days\")\n",
    "print(f\"{'MAE Gap':<20} {abs(test_mae_lstm - train_mae_lstm):.2f} days{'':<11} {abs(test_mae_lstm_v2 - train_mae_lstm_v2):.2f} days{'':<11} {abs(test_mae_lstm_v2 - train_mae_lstm_v2) - abs(test_mae_lstm - train_mae_lstm):+.2f} days\")\n",
    "print(f\"{'Test R²':<20} {test_r2_lstm:.4f}{'':<14} {test_r2_lstm_v2:.4f}{'':<14} {test_r2_lstm_v2 - test_r2_lstm:+.4f}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store results\n",
    "results.append({\n",
    "    'Model': 'LSTM V2 (Improved)',\n",
    "    'Train MAE': train_mae_lstm_v2,\n",
    "    'Test MAE': test_mae_lstm_v2,\n",
    "    'Train RMSE': train_rmse_lstm_v2,\n",
    "    'Test RMSE': test_rmse_lstm_v2,\n",
    "    'Train R²': train_r2_lstm_v2,\n",
    "    'Test R²': test_r2_lstm_v2\n",
    "})\n",
    "\n",
    "# Plot training history\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "ax1 = axes[0]\n",
    "ax1.plot(history_lstm_v2.history['loss'], label='Train Loss', linewidth=2)\n",
    "ax1.plot(history_lstm_v2.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "ax1.set_xlabel('Epoch', fontsize=11)\n",
    "ax1.set_ylabel('MAE Loss', fontsize=11)\n",
    "ax1.set_title('LSTM V2 Training History - Loss', fontweight='bold', fontsize=12)\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "\n",
    "ax2 = axes[1]\n",
    "ax2.plot(history_lstm_v2.history['mae'], label='Train MAE', linewidth=2)\n",
    "ax2.plot(history_lstm_v2.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "ax2.set_xlabel('Epoch', fontsize=11)\n",
    "ax2.set_ylabel('MAE', fontsize=11)\n",
    "ax2.set_title('LSTM V2 Training History - MAE', fontweight='bold', fontsize=12)\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 LSTM V2 - Alternative Architecture (Moderate Improvement)\n",
    "\n",
    "The deep architecture (256→128→64→32) was too complex. Let's try a more balanced approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"LSTM V2 - ALTERNATIVE ARCHITECTURE (MODERATE)\")\n",
    "print(\"=\"*80)\n",
    "print(\"Strategy: Slightly deeper than V1, but not too complex\")\n",
    "\n",
    "# Build moderate improvement - balance between V1 and deep V2\n",
    "lstm_v2_alt_model = Sequential([\n",
    "    # Similar to V1 but with slightly more capacity\n",
    "    LSTM(128, activation='relu', return_sequences=True, input_shape=(1, X_train_lstm.shape[2])),\n",
    "    Dropout(0.25),  # Slightly higher than V1's 0.2\n",
    "    \n",
    "    LSTM(64, activation='relu', return_sequences=True),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    LSTM(32, activation='relu'),\n",
    "    Dropout(0.25),\n",
    "    \n",
    "    Dense(24, activation='relu'),  # Larger dense layer\n",
    "    Dropout(0.2),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "# Compile with same learning rate as V1\n",
    "lstm_v2_alt_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='mae',\n",
    "    metrics=['mae', 'mse']\n",
    ")\n",
    "\n",
    "# Same callbacks as V1\n",
    "early_stopping_alt = EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True, verbose=1)\n",
    "reduce_lr_alt = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "print(\"\\nTraining alternative LSTM V2...\")\n",
    "history_lstm_v2_alt = lstm_v2_alt_model.fit(\n",
    "    X_train_lstm, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping_alt, reduce_lr_alt],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "y_pred_train_lstm_v2_alt = lstm_v2_alt_model.predict(X_train_lstm, verbose=0).flatten()\n",
    "y_pred_test_lstm_v2_alt = lstm_v2_alt_model.predict(X_test_lstm, verbose=0).flatten()\n",
    "\n",
    "train_mae_v2_alt = mean_absolute_error(y_train, y_pred_train_lstm_v2_alt)\n",
    "test_mae_v2_alt = mean_absolute_error(y_test, y_pred_test_lstm_v2_alt)\n",
    "train_r2_v2_alt = r2_score(y_train, y_pred_train_lstm_v2_alt)\n",
    "test_r2_v2_alt = r2_score(y_test, y_pred_test_lstm_v2_alt)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPARISON: V1 vs Deep V2 vs Alternative V2\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Metric':<20} {'V1':<15} {'Deep V2':<15} {'Alt V2':<15} {'Best':<10}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Test MAE':<20} {test_mae_lstm:<15.2f} {test_mae_lstm_v2:<15.2f} {test_mae_v2_alt:<15.2f} {'V1' if test_mae_lstm < min(test_mae_lstm_v2, test_mae_v2_alt) else ('Deep' if test_mae_lstm_v2 < test_mae_v2_alt else 'Alt'):<10}\")\n",
    "print(f\"{'MAE Gap':<20} {abs(test_mae_lstm - train_mae_lstm):<15.2f} {abs(test_mae_lstm_v2 - train_mae_lstm_v2):<15.2f} {abs(test_mae_v2_alt - train_mae_v2_alt):<15.2f} {'V1' if abs(test_mae_lstm - train_mae_lstm) < min(abs(test_mae_lstm_v2 - train_mae_lstm_v2), abs(test_mae_v2_alt - train_mae_v2_alt)) else ('Deep' if abs(test_mae_lstm_v2 - train_mae_lstm_v2) < abs(test_mae_v2_alt - train_mae_v2_alt) else 'Alt'):<10}\")\n",
    "print(f\"{'Test R²':<20} {test_r2_lstm:<15.4f} {test_r2_lstm_v2:<15.4f} {test_r2_v2_alt:<15.4f} {'V1' if test_r2_lstm > max(test_r2_lstm_v2, test_r2_v2_alt) else ('Deep' if test_r2_lstm_v2 > test_r2_v2_alt else 'Alt'):<10}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Determine best LSTM version\n",
    "if test_mae_v2_alt < test_mae_lstm:\n",
    "    print(\"\\n✓ Alternative V2 is better! Using it as LSTM V2\")\n",
    "    lstm_v2_model = lstm_v2_alt_model\n",
    "    y_pred_train_lstm_v2 = y_pred_train_lstm_v2_alt\n",
    "    y_pred_test_lstm_v2 = y_pred_test_lstm_v2_alt\n",
    "    train_mae_lstm_v2 = train_mae_v2_alt\n",
    "    test_mae_lstm_v2 = test_mae_v2_alt\n",
    "    train_r2_lstm_v2 = train_r2_v2_alt\n",
    "    test_r2_lstm_v2 = test_r2_v2_alt\n",
    "    history_lstm_v2 = history_lstm_v2_alt\n",
    "else:\n",
    "    print(f\"\\n→ V1 is still the best (Test MAE: {test_mae_lstm:.2f} days)\")\n",
    "    print(\"  Using LSTM V1 for final ensemble\")\n",
    "    lstm_v2_model = lstm_model\n",
    "    y_pred_train_lstm_v2 = y_pred_train_lstm\n",
    "    y_pred_test_lstm_v2 = y_pred_test_lstm\n",
    "    train_mae_lstm_v2 = train_mae_lstm\n",
    "    test_mae_lstm_v2 = test_mae_lstm\n",
    "    train_r2_lstm_v2 = train_r2_lstm\n",
    "    test_r2_lstm_v2 = test_r2_lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Final Ensemble with XGBoost V2 + LSTM V2\n",
    "\n",
    "Now that we have optimized versions of both key models, let's find the optimal weights for XGBoost V2 + LSTM V2 combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL ENSEMBLE OPTIMIZATION: XGBoost V2 + LSTM V2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Test weight combinations for 2-model ensemble\n",
    "final_ensemble_results = []\n",
    "\n",
    "for w_xgb in np.arange(0.0, 1.05, 0.05):\n",
    "    w_lstm = round(1.0 - w_xgb, 2)\n",
    "    \n",
    "    # Create ensemble predictions\n",
    "    y_pred_train_final = w_xgb * y_pred_train_xgb_v2 + w_lstm * y_pred_train_lstm_v2\n",
    "    y_pred_test_final = w_xgb * y_pred_test_xgb_v2 + w_lstm * y_pred_test_lstm_v2\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_mae = mean_absolute_error(y_train, y_pred_train_final)\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test_final)\n",
    "    train_r2 = r2_score(y_train, y_pred_train_final)\n",
    "    test_r2 = r2_score(y_test, y_pred_test_final)\n",
    "    mae_gap = test_mae - train_mae\n",
    "    r2_gap = train_r2 - test_r2\n",
    "    \n",
    "    final_ensemble_results.append({\n",
    "        'XGB_V2_Weight': w_xgb,\n",
    "        'LSTM_V2_Weight': w_lstm,\n",
    "        'Train_MAE': train_mae,\n",
    "        'Test_MAE': test_mae,\n",
    "        'MAE_Gap': mae_gap,\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2,\n",
    "        'R2_Gap': r2_gap\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_ensemble_df = pd.DataFrame(final_ensemble_results)\n",
    "\n",
    "# Composite score\n",
    "final_ensemble_df['Composite_Score'] = (\n",
    "    0.6 * (final_ensemble_df['Test_MAE'] - final_ensemble_df['Test_MAE'].min()) / \n",
    "          (final_ensemble_df['Test_MAE'].max() - final_ensemble_df['Test_MAE'].min()) +\n",
    "    0.4 * (final_ensemble_df['MAE_Gap'] - final_ensemble_df['MAE_Gap'].min()) / \n",
    "          (final_ensemble_df['MAE_Gap'].max() - final_ensemble_df['MAE_Gap'].min())\n",
    ")\n",
    "\n",
    "# Find optimal\n",
    "best_final = final_ensemble_df.nsmallest(1, 'Composite_Score').iloc[0]\n",
    "\n",
    "print(f\"\\nTested {len(final_ensemble_df)} weight combinations\")\n",
    "print(\"\\nTop 10 Configurations:\")\n",
    "print(final_ensemble_df.nsmallest(10, 'Composite_Score')[\n",
    "    ['XGB_V2_Weight', 'LSTM_V2_Weight', 'Test_MAE', 'MAE_Gap', 'Test_R2', 'Composite_Score']\n",
    "].to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OPTIMAL FINAL ENSEMBLE\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nBest Weights:\")\n",
    "print(f\"  XGBoost V2: {best_final['XGB_V2_Weight']:.0%}\")\n",
    "print(f\"  LSTM V2:    {best_final['LSTM_V2_Weight']:.0%}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  Test MAE:   {best_final['Test_MAE']:.2f} days\")\n",
    "print(f\"  MAE Gap:    {best_final['MAE_Gap']:.2f} days\")\n",
    "print(f\"  Test R²:    {best_final['Test_R2']:.4f}\")\n",
    "print(f\"  R² Gap:     {best_final['R2_Gap']:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Save Final Models\n",
    "\n",
    "Save all optimized models and components for production deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory\n",
    "models_dir = 'saved_models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# Generate timestamp\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING MODELS AND COMPONENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. Save XGBoost V2\n",
    "xgb_path = os.path.join(models_dir, f'xgboost_v2_{timestamp}.json')\n",
    "best_xgb_v2.save_model(xgb_path)\n",
    "print(f\"XGBoost V2 saved: {xgb_path}\")\n",
    "\n",
    "# 2. Save LSTM (Unidirectional LSTM V1 - the best performer)\n",
    "lstm_path = os.path.join(models_dir, f'lstm_{timestamp}.keras')\n",
    "lstm_v2_model.save(lstm_path)\n",
    "print(f\"LSTM saved: {lstm_path}\")\n",
    "\n",
    "# 3. Save scalers\n",
    "scaler_path = os.path.join(models_dir, f'scalers_{timestamp}.pkl')\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'standard_scaler': scaler,\n",
    "        'minmax_scaler': minmax_scaler\n",
    "    }, f)\n",
    "print(f\"Scalers saved: {scaler_path}\")\n",
    "\n",
    "# 4. Save feature columns\n",
    "features_path = os.path.join(models_dir, f'feature_columns_{timestamp}.pkl')\n",
    "with open(features_path, 'wb') as f:\n",
    "    pickle.dump(feature_columns, f)\n",
    "print(f\"Feature columns saved: {features_path}\")\n",
    "\n",
    "# 5. Save ensemble configuration (2-model ensemble)\n",
    "ensemble_config = {\n",
    "    'xgboost_v2_weight': best_final['XGB_V2_Weight'],\n",
    "    'lstm_weight': best_final['LSTM_V2_Weight'],\n",
    "    'test_mae': best_final['Test_MAE'],\n",
    "    'test_r2': best_final['Test_R2'],\n",
    "    'mae_gap': best_final['MAE_Gap'],\n",
    "    'r2_gap': best_final['R2_Gap'],\n",
    "    'timestamp': timestamp\n",
    "}\n",
    "\n",
    "config_path = os.path.join(models_dir, f'ensemble_config_{timestamp}.pkl')\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(ensemble_config, f)\n",
    "print(f\"Ensemble config saved: {config_path}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL MODELS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nSaved to directory: {os.path.abspath(models_dir)}\")\n",
    "print(f\"\\nOptimal 2-Model Ensemble:\")\n",
    "print(f\"  - XGBoost V2: {best_final['XGB_V2_Weight']:.0%}\")\n",
    "print(f\"  - LSTM:       {best_final['LSTM_V2_Weight']:.0%}\")\n",
    "print(f\"\\nPerformance:\")\n",
    "print(f\"  - Test MAE: {best_final['Test_MAE']:.2f} days\")\n",
    "print(f\"  - MAE Gap:  {best_final['MAE_Gap']:.2f} days\")\n",
    "print(f\"  - Test R²:  {best_final['Test_R2']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Prediction Function for New Orders\n",
    "\n",
    "Load the saved models and create a production-ready prediction function that can predict reorder dates for new orders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "\n",
    "class ReorderPredictor:\n",
    "    \"\"\"\n",
    "    Production-ready predictor for client reorder dates.\n",
    "    Uses optimized 2-model ensemble: XGBoost V2 + LSTM\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, models_dir='saved_models', timestamp=None):\n",
    "        \"\"\"Load all saved model components\"\"\"\n",
    "\n",
    "        # Auto-detect latest timestamp if not provided\n",
    "        if timestamp is None:\n",
    "            xgb_files = glob.glob(os.path.join(models_dir, 'xgboost_v2_*.json'))\n",
    "            if not xgb_files:\n",
    "                raise FileNotFoundError(f\"No XGBoost models found in {models_dir}\")\n",
    "            latest_xgb = max(xgb_files, key=os.path.getmtime)\n",
    "            timestamp = os.path.basename(latest_xgb).replace('xgboost_v2_', '').replace('.json', '')\n",
    "            print(f\"Auto-detected latest models with timestamp: {timestamp}\")\n",
    "\n",
    "        print(f\"Loading models with timestamp: {timestamp}...\")\n",
    "\n",
    "        # Load XGBoost V2\n",
    "        xgb_path = os.path.join(models_dir, f'xgboost_v2_{timestamp}.json')\n",
    "        self.xgb_model = XGBRegressor()\n",
    "        self.xgb_model.load_model(xgb_path)\n",
    "        print(f\"  XGBoost V2 loaded\")\n",
    "\n",
    "        # Load LSTM\n",
    "        lstm_path = os.path.join(models_dir, f'lstm_{timestamp}.keras')\n",
    "        self.lstm_model = keras.models.load_model(lstm_path)\n",
    "        print(f\"  LSTM loaded\")\n",
    "\n",
    "        # Load scalers\n",
    "        scaler_path = os.path.join(models_dir, f'scalers_{timestamp}.pkl')\n",
    "        with open(scaler_path, 'rb') as f:\n",
    "            scalers = pickle.load(f)\n",
    "        self.standard_scaler = scalers['standard_scaler']\n",
    "        self.minmax_scaler = scalers['minmax_scaler']\n",
    "        print(f\"  Scalers loaded\")\n",
    "\n",
    "        # Load feature columns\n",
    "        features_path = os.path.join(models_dir, f'feature_columns_{timestamp}.pkl')\n",
    "        with open(features_path, 'rb') as f:\n",
    "            self.feature_columns = pickle.load(f)\n",
    "        print(f\"  Feature columns loaded ({len(self.feature_columns)} features)\")\n",
    "\n",
    "        # Load ensemble config\n",
    "        config_path = os.path.join(models_dir, f'ensemble_config_{timestamp}.pkl')\n",
    "        with open(config_path, 'rb') as f:\n",
    "            self.ensemble_config = pickle.load(f)\n",
    "        self.xgb_weight = self.ensemble_config['xgboost_v2_weight']\n",
    "        self.lstm_weight = self.ensemble_config['lstm_weight']\n",
    "        print(f\"  Ensemble weights: XGB={self.xgb_weight:.0%}, LSTM={self.lstm_weight:.0%}\")\n",
    "\n",
    "        print(f\"\\nAll models loaded successfully!\")\n",
    "        print(f\"Test MAE: {self.ensemble_config['test_mae']:.2f} days\")\n",
    "        print(f\"MAE Gap: {self.ensemble_config['mae_gap']:.2f} days\")\n",
    "        print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "    def predict(self, X_new):\n",
    "        \"\"\"\n",
    "        Predict days until next order for new data\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        X_new : DataFrame or array-like\n",
    "            Features for new orders (must have same columns as training)\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        predictions : array\n",
    "            Predicted days until next order\n",
    "        \"\"\"\n",
    "        # Ensure X_new is a DataFrame\n",
    "        if not isinstance(X_new, pd.DataFrame):\n",
    "            X_new = pd.DataFrame(X_new, columns=self.feature_columns)\n",
    "\n",
    "        # Ensure correct column order\n",
    "        X_new = X_new[self.feature_columns]\n",
    "\n",
    "        # Scale features for XGBoost (StandardScaler)\n",
    "        X_scaled_xgb = self.standard_scaler.transform(X_new)\n",
    "\n",
    "        # Scale features for LSTM (MinMaxScaler)\n",
    "        X_scaled_lstm = self.minmax_scaler.transform(X_new)\n",
    "        X_scaled_lstm_reshaped = X_scaled_lstm.reshape((X_scaled_lstm.shape[0], 1, X_scaled_lstm.shape[1]))\n",
    "\n",
    "        # Get predictions from both models\n",
    "        xgb_pred = self.xgb_model.predict(X_scaled_xgb)\n",
    "        lstm_pred = self.lstm_model.predict(X_scaled_lstm_reshaped, verbose=0).flatten()\n",
    "\n",
    "        # 2-model ensemble prediction\n",
    "        ensemble_pred = self.xgb_weight * xgb_pred + self.lstm_weight * lstm_pred\n",
    "\n",
    "        return ensemble_pred\n",
    "\n",
    "    def predict_reorder_dates(self, df, current_order_date_col='order_date'):\n",
    "        \"\"\"\n",
    "        Predict actual reorder dates (not just days)\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        df : DataFrame\n",
    "            Data with features and current order date\n",
    "        current_order_date_col : str\n",
    "            Column name containing the current order date\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        DataFrame with predictions\n",
    "        \"\"\"\n",
    "        # Extract features\n",
    "        X_new = df[self.feature_columns]\n",
    "\n",
    "        # Predict days until next order\n",
    "        days_pred = self.predict(X_new)\n",
    "\n",
    "        # Calculate predicted reorder dates\n",
    "        current_dates = pd.to_datetime(df[current_order_date_col])\n",
    "        predicted_dates = current_dates + pd.to_timedelta(days_pred, unit='D')\n",
    "\n",
    "        # Create results DataFrame\n",
    "        results = df.copy()\n",
    "        results['predicted_days_until_reorder'] = days_pred.round(1)\n",
    "        results['predicted_reorder_date'] = predicted_dates\n",
    "        results['confidence'] = self._calculate_confidence(days_pred)\n",
    "\n",
    "        return results\n",
    "\n",
    "    def _calculate_confidence(self, predictions):\n",
    "        \"\"\"\n",
    "        Calculate confidence scores based on prediction stability\n",
    "        (simplified version - can be enhanced with prediction intervals)\n",
    "        \"\"\"\n",
    "        # Simple confidence: inverse of prediction magnitude (normalized)\n",
    "        confidence = np.clip(1 - (predictions - predictions.mean()) / (predictions.std() * 2), 0.5, 1.0)\n",
    "        return confidence.round(2)\n",
    "\n",
    "# Initialize predictor (auto-detects latest models)\n",
    "print(\"=\"*80)\n",
    "print(\"INITIALIZING 2-MODEL ENSEMBLE PREDICTOR\")\n",
    "print(\"=\"*80)\n",
    "predictor = ReorderPredictor(models_dir='saved_models')\n",
    "\n",
    "print(\"PREDICTOR READY FOR USE\")\n",
    "print(\"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"TESTING PREDICTOR ON SAMPLE DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load the data\n",
    "df_full = pd.read_excel('soya_data_cleaned_2023_onwards.xlsx')\n",
    "\n",
    "# Filter for Small and Medium orders (0-10 TM)\n",
    "df_filtered = df_full[(df_full['total_amount_ordered_tm'] > 0) & (df_full['total_amount_ordered_tm'] <= 10)].copy()\n",
    "\n",
    "# Ensure we have the required features\n",
    "required_features = predictor.feature_columns\n",
    "\n",
    "# Check if features exist\n",
    "available_features = [col for col in required_features if col in df_filtered.columns]\n",
    "\n",
    "if len(available_features) == len(required_features):\n",
    "    print(f\"\\nAll {len(required_features)} features available in data\")\n",
    "\n",
    "    # Sample 10 random records\n",
    "    sample_data = df_filtered[required_features].sample(n=10, random_state=42)\n",
    "    sample_data_with_date = sample_data.copy()\n",
    "    sample_data_with_date['order_date'] = pd.Timestamp('2024-11-01')\n",
    "\n",
    "    # Get predictions\n",
    "    predictions_df = predictor.predict_reorder_dates(sample_data_with_date, current_order_date_col='order_date')\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nSample Predictions:\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "    results_display = predictions_df[['predicted_days_until_reorder', 'predicted_reorder_date', 'confidence']].copy()\n",
    "    results_display.columns = ['Days Until Reorder', 'Predicted Date', 'Confidence']\n",
    "\n",
    "    print(results_display.to_string(index=False))\n",
    "\n",
    "    print(f\"\\nAverage predicted days: {predictions_df['predicted_days_until_reorder'].mean():.1f}\")\n",
    "    print(f\"Average confidence: {predictions_df['confidence'].mean():.2f}\")\n",
    "else:\n",
    "    print(f\"\\nWarning: Only {len(available_features)}/{len(required_features)} features available\")\n",
    "    print(\"This is a demo - in production, ensure all features are properly engineered\")\n",
    "\n",
    "    # For demo purposes, use the available features\n",
    "    print(\"\\nNote: To get accurate predictions, you need to run the entire notebook\")\n",
    "    print(\"      from the beginning to generate all required features.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Feature Importance Analysis\n",
    "\n",
    "Understand which features drive the predictions - this helps explain the model to stakeholders and identify key business drivers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Get feature importance from XGBoost V2\n",
    "xgb_importance = best_xgb_v2.feature_importances_\n",
    "\n",
    "# Create DataFrame\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': xgb_importance\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Calculate percentage\n",
    "feature_importance_df['Importance_Pct'] = (feature_importance_df['Importance'] / feature_importance_df['Importance'].sum() * 100)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(\"-\" * 80)\n",
    "print(feature_importance_df.head(15).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Top 15 features bar chart\n",
    "top_features = feature_importance_df.head(15)\n",
    "axes[0].barh(range(len(top_features)), top_features['Importance'], color='steelblue')\n",
    "axes[0].set_yticks(range(len(top_features)))\n",
    "axes[0].set_yticklabels(top_features['Feature'])\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_xlabel('Importance Score', fontsize=11)\n",
    "axes[0].set_title('Top 15 Feature Importance (XGBoost V2)', fontsize=13, fontweight='bold')\n",
    "axes[0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Cumulative importance\n",
    "feature_importance_df['Cumulative_Pct'] = feature_importance_df['Importance_Pct'].cumsum()\n",
    "axes[1].plot(range(len(feature_importance_df)), feature_importance_df['Cumulative_Pct'], \n",
    "             marker='o', linewidth=2, markersize=4, color='steelblue')\n",
    "axes[1].axhline(y=80, color='red', linestyle='--', linewidth=1.5, label='80% threshold')\n",
    "axes[1].axhline(y=90, color='orange', linestyle='--', linewidth=1.5, label='90% threshold')\n",
    "axes[1].set_xlabel('Number of Features', fontsize=11)\n",
    "axes[1].set_ylabel('Cumulative Importance (%)', fontsize=11)\n",
    "axes[1].set_title('Cumulative Feature Importance', fontsize=13, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# How many features for 80% and 90%\n",
    "features_80 = len(feature_importance_df[feature_importance_df['Cumulative_Pct'] <= 80])\n",
    "features_90 = len(feature_importance_df[feature_importance_df['Cumulative_Pct'] <= 90])\n",
    "\n",
    "print(f\"\\nFeatures needed for 80% of importance: {features_80}/{len(feature_columns)}\")\n",
    "print(f\"Features needed for 90% of importance: {features_90}/{len(feature_columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE INTERPRETATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Group features by category\n",
    "feature_categories = {\n",
    "    'RFM': ['recency', 'frequency', 'monetary_value'],\n",
    "    'Rolling Windows': [col for col in feature_columns if 'rolling' in col.lower()],\n",
    "    'Client Aggregates': [col for col in feature_columns if 'client_' in col.lower()],\n",
    "    'Order Details': [col for col in feature_columns if any(x in col.lower() for x in ['quantity', 'tm_', 'price'])],\n",
    "    'Temporal': [col for col in feature_columns if any(x in col.lower() for x in ['month', 'quarter', 'year', 'day'])]\n",
    "}\n",
    "\n",
    "# Calculate category importance\n",
    "category_importance = {}\n",
    "for category, features in feature_categories.items():\n",
    "    category_features = [f for f in features if f in feature_importance_df['Feature'].values]\n",
    "    total_importance = feature_importance_df[feature_importance_df['Feature'].isin(category_features)]['Importance_Pct'].sum()\n",
    "    category_importance[category] = total_importance\n",
    "\n",
    "# Sort and display\n",
    "category_df = pd.DataFrame(list(category_importance.items()), columns=['Category', 'Total_Importance_Pct'])\n",
    "category_df = category_df.sort_values('Total_Importance_Pct', ascending=False)\n",
    "\n",
    "print(\"\\nImportance by Feature Category:\")\n",
    "print(\"-\" * 80)\n",
    "for idx, row in category_df.iterrows():\n",
    "    print(f\"{row['Category']:<20} {row['Total_Importance_Pct']:>6.2f}%\")\n",
    "\n",
    "# Key insights\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"KEY INSIGHTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "top_feature = feature_importance_df.iloc[0]\n",
    "print(f\"\\n1. Most Important Feature: {top_feature['Feature']}\")\n",
    "print(f\"   - Contributes {top_feature['Importance_Pct']:.2f}% to predictions\")\n",
    "\n",
    "top_category = category_df.iloc[0]\n",
    "print(f\"\\n2. Most Important Category: {top_category['Category']}\")\n",
    "print(f\"   - Contributes {top_category['Total_Importance_Pct']:.2f}% to predictions\")\n",
    "\n",
    "print(f\"\\n3. Feature Efficiency:\")\n",
    "print(f\"   - {features_80} features ({features_80/len(feature_columns)*100:.1f}%) explain 80% of predictions\")\n",
    "print(f\"   - {features_90} features ({features_90/len(feature_columns)*100:.1f}%) explain 90% of predictions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. Client-Specific Dashboard\n",
    "\n",
    "Create interactive dashboards showing predicted reorder dates for each client, helping sales teams proactively reach out to customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"GENERATING CLIENT PREDICTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use test set for demonstration (in production, use latest client orders)\n",
    "demo_data = X_test.head(50).copy()\n",
    "demo_data['order_date'] = pd.Timestamp('2024-11-01')  # Mock current date\n",
    "\n",
    "# Get predictions\n",
    "client_predictions = predictor.predict_reorder_dates(demo_data, current_order_date_col='order_date')\n",
    "\n",
    "# Add mock client names\n",
    "client_predictions['client_name'] = [f'Client_{i:03d}' for i in range(1, len(client_predictions)+1)]\n",
    "\n",
    "# Add risk category\n",
    "def categorize_urgency(days):\n",
    "    if days <= 7:\n",
    "        return 'High Priority (< 7 days)'\n",
    "    elif days <= 14:\n",
    "        return 'Medium Priority (7-14 days)'\n",
    "    elif days <= 30:\n",
    "        return 'Low Priority (14-30 days)'\n",
    "    else:\n",
    "        return 'Monitor (> 30 days)'\n",
    "\n",
    "client_predictions['urgency'] = client_predictions['predicted_days_until_reorder'].apply(categorize_urgency)\n",
    "client_predictions = client_predictions.sort_values('predicted_days_until_reorder')\n",
    "\n",
    "print(f\"\\nGenerated predictions for {len(client_predictions)} clients\")\n",
    "print(\"\\nUrgency Distribution:\")\n",
    "print(client_predictions['urgency'].value_counts().to_string())\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CLIENT REORDER DASHBOARD - TOP 20 URGENT CLIENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Display top 20 most urgent clients\n",
    "top_urgent = client_predictions.head(20)[[\n",
    "    'client_name', \n",
    "    'predicted_days_until_reorder', \n",
    "    'predicted_reorder_date',\n",
    "    'confidence',\n",
    "    'urgency'\n",
    "]].copy()\n",
    "\n",
    "top_urgent.columns = ['Client', 'Days Until Reorder', 'Predicted Date', 'Confidence', 'Urgency']\n",
    "\n",
    "print(\"\\n\" + top_urgent.to_string(index=False))\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive dashboard visualizations\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Urgency Distribution (Pie Chart)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "urgency_counts = client_predictions['urgency'].value_counts()\n",
    "colors = ['#d62728', '#ff7f0e', '#2ca02c', '#1f77b4']\n",
    "ax1.pie(urgency_counts.values, labels=urgency_counts.index, autopct='%1.1f%%', \n",
    "        colors=colors, startangle=90)\n",
    "ax1.set_title('Client Urgency Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 2. Days Until Reorder Distribution\n",
    "ax2 = fig.add_subplot(gs[0, 1:])\n",
    "ax2.hist(client_predictions['predicted_days_until_reorder'], bins=30, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax2.axvline(7, color='red', linestyle='--', linewidth=2, label='7 days')\n",
    "ax2.axvline(14, color='orange', linestyle='--', linewidth=2, label='14 days')\n",
    "ax2.axvline(30, color='green', linestyle='--', linewidth=2, label='30 days')\n",
    "ax2.set_xlabel('Predicted Days Until Reorder', fontsize=10)\n",
    "ax2.set_ylabel('Number of Clients', fontsize=10)\n",
    "ax2.set_title('Distribution of Predicted Reorder Times', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "# 3. Timeline View - Next 30 Days\n",
    "ax3 = fig.add_subplot(gs[1, :])\n",
    "next_30_days = client_predictions[client_predictions['predicted_days_until_reorder'] <= 30].sort_values('predicted_days_until_reorder')\n",
    "urgency_colors = {\n",
    "    'High Priority (< 7 days)': '#d62728',\n",
    "    'Medium Priority (7-14 days)': '#ff7f0e',\n",
    "    'Low Priority (14-30 days)': '#2ca02c'\n",
    "}\n",
    "colors_list = [urgency_colors.get(u, 'gray') for u in next_30_days['urgency']]\n",
    "\n",
    "ax3.barh(range(len(next_30_days)), next_30_days['predicted_days_until_reorder'], color=colors_list, alpha=0.7)\n",
    "ax3.set_yticks(range(len(next_30_days)))\n",
    "ax3.set_yticklabels(next_30_days['client_name'], fontsize=8)\n",
    "ax3.set_xlabel('Days Until Predicted Reorder', fontsize=10)\n",
    "ax3.set_title(f'Reorder Timeline - Next 30 Days ({len(next_30_days)} Clients)', fontsize=12, fontweight='bold')\n",
    "ax3.axvline(7, color='red', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax3.axvline(14, color='orange', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax3.grid(axis='x', alpha=0.3)\n",
    "ax3.invert_yaxis()\n",
    "\n",
    "# 4. Confidence Distribution\n",
    "ax4 = fig.add_subplot(gs[2, 0])\n",
    "ax4.hist(client_predictions['confidence'], bins=20, color='purple', edgecolor='black', alpha=0.7)\n",
    "ax4.set_xlabel('Confidence Score', fontsize=10)\n",
    "ax4.set_ylabel('Number of Clients', fontsize=10)\n",
    "ax4.set_title('Prediction Confidence Distribution', fontsize=12, fontweight='bold')\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# 5. Days vs Confidence Scatter\n",
    "ax5 = fig.add_subplot(gs[2, 1])\n",
    "scatter = ax5.scatter(client_predictions['predicted_days_until_reorder'], \n",
    "                     client_predictions['confidence'],\n",
    "                     c=client_predictions['predicted_days_until_reorder'],\n",
    "                     cmap='RdYlGn_r', alpha=0.6, s=50)\n",
    "ax5.set_xlabel('Predicted Days', fontsize=10)\n",
    "ax5.set_ylabel('Confidence', fontsize=10)\n",
    "ax5.set_title('Days vs Confidence', fontsize=12, fontweight='bold')\n",
    "ax5.grid(alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax5, label='Days')\n",
    "\n",
    "# 6. Summary Statistics\n",
    "ax6 = fig.add_subplot(gs[2, 2])\n",
    "ax6.axis('off')\n",
    "\n",
    "summary_text = f\"\"\"\n",
    "SUMMARY STATISTICS\n",
    "{'-'*30}\n",
    "\n",
    "Total Clients: {len(client_predictions)}\n",
    "\n",
    "Urgency Breakdown:\n",
    "  High Priority:   {len(client_predictions[client_predictions['urgency'].str.contains('High')])}\n",
    "  Medium Priority: {len(client_predictions[client_predictions['urgency'].str.contains('Medium')])}\n",
    "  Low Priority:    {len(client_predictions[client_predictions['urgency'].str.contains('Low')])}\n",
    "  Monitor:         {len(client_predictions[client_predictions['urgency'].str.contains('Monitor')])}\n",
    "\n",
    "Avg Days to Reorder: {client_predictions['predicted_days_until_reorder'].mean():.1f}\n",
    "Min Days: {client_predictions['predicted_days_until_reorder'].min():.1f}\n",
    "Max Days: {client_predictions['predicted_days_until_reorder'].max():.1f}\n",
    "\n",
    "Avg Confidence: {client_predictions['confidence'].mean():.2f}\n",
    "\"\"\"\n",
    "\n",
    "ax6.text(0.1, 0.9, summary_text, transform=ax6.transAxes, fontsize=10,\n",
    "        verticalalignment='top', fontfamily='monospace',\n",
    "        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.suptitle('CLIENT REORDER PREDICTION DASHBOARD', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDashboard generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"EXPORTING PREDICTIONS FOR SALES TEAM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create export file\n",
    "export_df = client_predictions[[\n",
    "    'client_name',\n",
    "    'predicted_days_until_reorder',\n",
    "    'predicted_reorder_date',\n",
    "    'confidence',\n",
    "    'urgency'\n",
    "]].copy()\n",
    "\n",
    "# Add action recommendations\n",
    "def get_action(urgency):\n",
    "    if 'High' in urgency:\n",
    "        return 'Call immediately - likely to reorder within a week'\n",
    "    elif 'Medium' in urgency:\n",
    "        return 'Schedule follow-up call this week'\n",
    "    elif 'Low' in urgency:\n",
    "        return 'Send email reminder'\n",
    "    else:\n",
    "        return 'Monitor - no action needed yet'\n",
    "\n",
    "export_df['recommended_action'] = export_df['urgency'].apply(get_action)\n",
    "\n",
    "# Rename columns\n",
    "export_df.columns = [\n",
    "    'Client Name',\n",
    "    'Predicted Days Until Reorder',\n",
    "    'Expected Reorder Date',\n",
    "    'Prediction Confidence',\n",
    "    'Priority Level',\n",
    "    'Recommended Action'\n",
    "]\n",
    "\n",
    "# Save to Excel\n",
    "output_file = 'client_reorder_predictions.xlsx'\n",
    "export_df.to_excel(output_file, index=False, sheet_name='Reorder Predictions')\n",
    "\n",
    "print(f\"\\nPredictions exported to: {output_file}\")\n",
    "print(f\"Total clients: {len(export_df)}\")\n",
    "print(f\"\\nFile includes:\")\n",
    "print(\"  - Client names\")\n",
    "print(\"  - Predicted reorder dates\")\n",
    "print(\"  - Confidence scores\")\n",
    "print(\"  - Priority levels\")\n",
    "print(\"  - Recommended actions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL SECTIONS COMPLETE!\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
