{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ðŸš€ Optimized Bidirectional LSTM for Order Prediction\n",
    "## Focus: BiLSTM with Comprehensive Model Management\n",
    "\n",
    "### Current Performance (Your Results):\n",
    "- âœ… **MAE: 3.59 days** (Excellent! Much better than baseline 6.17)\n",
    "- âœ… **Within 7 days: 91.9%** (Outstanding accuracy)\n",
    "- âœ… **Within 14 days: 96.3%** (Very high precision)\n",
    "\n",
    "### This Notebook Includes:\n",
    "1. **Enhanced BiLSTM Architecture** (building on your success)\n",
    "2. **Comprehensive Model Saving** (multiple formats)\n",
    "3. **Model Versioning & Checkpointing**\n",
    "4. **Easy Model Loading & Inference**\n",
    "5. **Performance Monitoring & Logging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy matplotlib seaborn scikit-learn tensorflow keras -q\n",
    "\n",
    "print(\"âœ… All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import (\n",
    "    LSTM, Bidirectional, Dense, Dropout, \n",
    "    BatchNormalization, Attention\n",
    ")\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping, ReduceLROnPlateau, \n",
    "    ModelCheckpoint, CSVLogger, TensorBoard\n",
    ")\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"ðŸ“¦ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"ðŸŽ² Random seed set to: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config",
   "metadata": {},
   "source": [
    "## ðŸ”§ Configuration & Model Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-dirs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory structure for model management\n",
    "MODEL_DIR = 'models'\n",
    "CHECKPOINT_DIR = os.path.join(MODEL_DIR, 'checkpoints')\n",
    "LOGS_DIR = os.path.join(MODEL_DIR, 'logs')\n",
    "SCALER_DIR = os.path.join(MODEL_DIR, 'scalers')\n",
    "METADATA_DIR = os.path.join(MODEL_DIR, 'metadata')\n",
    "\n",
    "# Create directories\n",
    "for directory in [MODEL_DIR, CHECKPOINT_DIR, LOGS_DIR, SCALER_DIR, METADATA_DIR]:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'bilstm_order_prediction',\n",
    "    'version': '1.0',\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'test_size': 0.2,\n",
    "    'validation_split': 0.15,\n",
    "    'batch_size': 64,\n",
    "    'epochs': 150,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience_early_stop': 20,\n",
    "    'patience_reduce_lr': 10,\n",
    "}\n",
    "\n",
    "print(\"âœ… Directory structure created:\")\n",
    "print(f\"   ðŸ“ Models: {MODEL_DIR}\")\n",
    "print(f\"   ðŸ“ Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"   ðŸ“ Logs: {LOGS_DIR}\")\n",
    "print(f\"   ðŸ“ Scalers: {SCALER_DIR}\")\n",
    "print(f\"   ðŸ“ Metadata: {METADATA_DIR}\")\n",
    "print(f\"\\nâš™ï¸  Configuration loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-eng-header",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Enhanced Feature Engineering\n",
    "### Based on your successful implementation + additional improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_enhanced_features(df):\n",
    "    \"\"\"\n",
    "    Create enhanced features optimized for BiLSTM\n",
    "    Based on your successful implementation (3.59 MAE)\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert dates\n",
    "    df['sales_order_creation_date'] = pd.to_datetime(df['sales_order_creation_date'])\n",
    "    df['actual_expedition_date'] = pd.to_datetime(df['actual_expedition_date'])\n",
    "    \n",
    "    # Sort by client and ORDER CREATION date (when client placed order)\n",
    "    # This is crucial - we predict when they'll PLACE next order, not when it delivers\n",
    "    df = df.sort_values(['client_name', 'sales_order_creation_date'])\n",
    "    \n",
    "    print(\"Creating features...\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 1. CORE TEMPORAL FEATURES (Most Important)\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Days since last order\n",
    "    df['days_since_last_order'] = df.groupby('client_name')['sales_order_creation_date'].diff().dt.days\n",
    "    \n",
    "    # Historical statistics\n",
    "    df['days_since_last_order_mean'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "        lambda x: x.expanding().mean()\n",
    "    )\n",
    "    df['days_since_last_order_std'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "        lambda x: x.expanding().std()\n",
    "    )\n",
    "    df['days_since_last_order_min'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "        lambda x: x.expanding().min()\n",
    "    )\n",
    "    df['days_since_last_order_max'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "        lambda x: x.expanding().max()\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 2. CLIENT BEHAVIOR METRICS\n",
    "    # ========================================================================z\n",
    "    \n",
    "    # Order sequence and frequency\n",
    "    df['order_sequence'] = df.groupby('client_name').cumcount() + 1\n",
    "    # Use ORDER CREATION dates for client lifetime (reordering timeline)\n",
    "    df['client_lifetime_days'] = df.groupby('client_name')['sales_order_creation_date'].transform(\n",
    "        lambda x: (x - x.min()).dt.days\n",
    "    )\n",
    "    df['order_frequency_per_month'] = (df['order_sequence'] / (df['client_lifetime_days'] / 30)).replace(\n",
    "        [np.inf, -np.inf], 0\n",
    "    )\n",
    "    \n",
    "    # Order counts\n",
    "    df['total_amount_delivered_tm_count'] = df.groupby('client_name').cumcount() + 1\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 3. ROLLING WINDOW FEATURES (Multiple Horizons)\n",
    "    # ========================================================================\n",
    "    \n",
    "    for window in [3, 5, 7, 10]:\n",
    "        # Days between orders\n",
    "        df[f'rolling_avg_days_{window}'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'rolling_std_days_{window}'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "        \n",
    "        # Quantity patterns\n",
    "        df[f'rolling_avg_quantity_{window}'] = df.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'rolling_std_quantity_{window}'] = df.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 4. TREND & MOMENTUM FEATURES\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Ordering frequency trend\n",
    "    df['order_frequency_trend'] = df.groupby('client_name')['order_frequency_per_month'].transform(\n",
    "        lambda x: x.diff()\n",
    "    )\n",
    "    \n",
    "    # Days since last order trend\n",
    "    df['days_trend'] = df.groupby('client_name')['days_since_last_order'].transform(\n",
    "        lambda x: x.diff()\n",
    "    )\n",
    "    \n",
    "    # Quantity trend\n",
    "    df['quantity_trend'] = df.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "        lambda x: x.diff()\n",
    "    )\n",
    "    \n",
    "    # Recent vs historical comparison\n",
    "    df['recent_vs_historical_frequency'] = df['rolling_avg_days_3'] / (df['days_since_last_order_mean'] + 1)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 5. CLIENT MATURITY & CONSISTENCY\n",
    "    # ========================================================================\n",
    "    \n",
    "    # Maturity level\n",
    "    df['client_maturity'] = pd.cut(\n",
    "        df['total_amount_delivered_tm_count'],\n",
    "        bins=[0, 5, 20, np.inf],\n",
    "        labels=[0, 1, 2]  # 0=new, 1=established, 2=veteran\n",
    "    ).astype(int)\n",
    "    \n",
    "    # Consistency score (inverse of coefficient of variation)\n",
    "    df['ordering_consistency'] = df['days_since_last_order_mean'] / (df['days_since_last_order_std'] + 1)\n",
    "    \n",
    "    # High frequency flag\n",
    "    df['is_high_frequency'] = (df['order_frequency_per_month'] > df['order_frequency_per_month'].median()).astype(int)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 6. QUANTITY FEATURES\n",
    "    # ========================================================================\n",
    "    \n",
    "    df['total_amount_delivered_tm_mean'] = df.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "        lambda x: x.expanding().mean()\n",
    "    )\n",
    "    df['total_amount_delivered_tm_std'] = df.groupby('client_name')['total_amount_delivered_tm'].transform(\n",
    "        lambda x: x.expanding().std()\n",
    "    )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 7. MINIMAL TEMPORAL CONTEXT (Lower priority but keep for context)\n",
    "    # ========================================================================\n",
    "    # Use ORDER CREATION dates (when client placed order, not delivery date)\n",
    "    df['order_month'] = df['sales_order_creation_date'].dt.month\n",
    "    df['order_quarter'] = df['sales_order_creation_date'].dt.quarter\n",
    "    df['order_day_of_month'] = df['sales_order_creation_date'].dt.day\n",
    "    \n",
    "    # ========================================================================\n",
    "    # 8. TARGET VARIABLE\n",
    "    # ========================================================================\n",
    "    \n",
    "    df['days_until_next_order'] = df.groupby('client_name')['days_since_last_order'].shift(-1)\n",
    "    \n",
    "    # Fill missing values\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df[numeric_cols] = df[numeric_cols].fillna(0)\n",
    "    \n",
    "    print(f\"âœ… Feature engineering complete!\")\n",
    "    print(f\"   Total features created: {len(numeric_cols)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ… Feature engineering function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-selection-header",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Intelligent Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features():\n",
    "    \"\"\"\n",
    "    Select features optimized for BiLSTM based on importance analysis\n",
    "    \"\"\"\n",
    "    \n",
    "    # HIGH PRIORITY - Core temporal features\n",
    "    core_features = [\n",
    "        'days_since_last_order',\n",
    "        'days_since_last_order_mean',\n",
    "        'days_since_last_order_std',\n",
    "        'days_since_last_order_min',\n",
    "        'days_since_last_order_max',\n",
    "    ]\n",
    "    \n",
    "    # HIGH PRIORITY - Client behavior\n",
    "    behavior_features = [\n",
    "        'order_frequency_per_month',\n",
    "        'total_amount_delivered_tm_count',\n",
    "        'order_sequence',\n",
    "        'client_lifetime_days',\n",
    "    ]\n",
    "    \n",
    "    # MEDIUM PRIORITY - Rolling windows (multiple horizons)\n",
    "    rolling_features = []\n",
    "    for window in [3, 5, 7, 10]:\n",
    "        rolling_features.extend([\n",
    "            f'rolling_avg_days_{window}',\n",
    "            f'rolling_std_days_{window}',\n",
    "            f'rolling_avg_quantity_{window}',\n",
    "            f'rolling_std_quantity_{window}',\n",
    "        ])\n",
    "    \n",
    "    # MEDIUM PRIORITY - Trends\n",
    "    trend_features = [\n",
    "        'order_frequency_trend',\n",
    "        'days_trend',\n",
    "        'quantity_trend',\n",
    "        'recent_vs_historical_frequency',\n",
    "    ]\n",
    "    \n",
    "    # LOW PRIORITY - Consistency & maturity\n",
    "    meta_features = [\n",
    "        'client_maturity',\n",
    "        'ordering_consistency',\n",
    "        'is_high_frequency',\n",
    "    ]\n",
    "    \n",
    "    # LOW PRIORITY - Quantity\n",
    "    quantity_features = [\n",
    "        'total_amount_delivered_tm',\n",
    "        'total_amount_delivered_tm_mean',\n",
    "        'total_amount_delivered_tm_std',\n",
    "    ]\n",
    "    \n",
    "    # MINIMAL - Temporal context\n",
    "    temporal_features = [\n",
    "        'order_month',\n",
    "        'order_quarter',\n",
    "        'order_day_of_month',\n",
    "    ]\n",
    "    \n",
    "    # Combine all\n",
    "    selected_features = (\n",
    "        core_features + \n",
    "        behavior_features + \n",
    "        rolling_features + \n",
    "        trend_features + \n",
    "        meta_features + \n",
    "        quantity_features + \n",
    "        temporal_features\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Feature Selection Summary:\")\n",
    "    print(f\"   Core Temporal: {len(core_features)}\")\n",
    "    print(f\"   Behavior: {len(behavior_features)}\")\n",
    "    print(f\"   Rolling Windows: {len(rolling_features)}\")\n",
    "    print(f\"   Trends: {len(trend_features)}\")\n",
    "    print(f\"   Meta: {len(meta_features)}\")\n",
    "    print(f\"   Quantity: {len(quantity_features)}\")\n",
    "    print(f\"   Temporal: {len(temporal_features)}\")\n",
    "    print(f\"   \" + \"=\"*50)\n",
    "    print(f\"   Total Selected: {len(selected_features)}\")\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "print(\"âœ… Feature selection function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-prep-header",
   "metadata": {},
   "source": [
    "## ðŸ”§ Data Preparation with Model Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_lstm(df, selected_features, config):\n",
    "    \"\"\"\n",
    "    Prepare data for LSTM with scaler persistence\n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove rows without target\n",
    "    df_clean = df.dropna(subset=['days_until_next_order']).copy()\n",
    "    \n",
    "    # Separate features and target\n",
    "    X = df_clean[selected_features].copy()\n",
    "    y = df_clean['days_until_next_order'].copy()\n",
    "    \n",
    "    # Split data (temporal split - no shuffle)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=config['test_size'], \n",
    "        random_state=config['random_seed'],\n",
    "        shuffle=False  # Preserve temporal order\n",
    "    )\n",
    "    \n",
    "    # Scale features using RobustScaler (better for outliers)\n",
    "    scaler = RobustScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Reshape for LSTM: (samples, timesteps, features)\n",
    "    X_train_lstm = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "    X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "    \n",
    "    # Save scaler\n",
    "    scaler_path = os.path.join(SCALER_DIR, 'feature_scaler.pkl')\n",
    "    with open(scaler_path, 'wb') as f:\n",
    "        pickle.dump(scaler, f)\n",
    "    print(f\"\\nðŸ’¾ Scaler saved to: {scaler_path}\")\n",
    "    \n",
    "    # Save feature names\n",
    "    feature_path = os.path.join(METADATA_DIR, 'feature_names.json')\n",
    "    with open(feature_path, 'w') as f:\n",
    "        json.dump(selected_features, f, indent=2)\n",
    "    print(f\"ðŸ’¾ Feature names saved to: {feature_path}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Data Preparation Summary:\")\n",
    "    print(f\"   Training samples: {X_train_lstm.shape[0]:,}\")\n",
    "    print(f\"   Test samples: {X_test_lstm.shape[0]:,}\")\n",
    "    print(f\"   Number of features: {X_train_lstm.shape[2]}\")\n",
    "    print(f\"   LSTM input shape: {X_train_lstm.shape}\")\n",
    "    print(f\"   Target mean (train): {y_train.mean():.2f} days\")\n",
    "    print(f\"   Target std (train): {y_train.std():.2f} days\")\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train_lstm,\n",
    "        'X_test': X_test_lstm,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': selected_features\n",
    "    }\n",
    "\n",
    "print(\"âœ… Data preparation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## ðŸ§  Enhanced Bidirectional LSTM Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "build-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_enhanced_bilstm(input_shape, config):\n",
    "    \"\"\"\n",
    "    Build enhanced BiLSTM based on your successful architecture\n",
    "    Optimized for 3.59 MAE performance\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "        # First Bidirectional LSTM layer with attention\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                128,\n",
    "                return_sequences=True,\n",
    "                kernel_regularizer=l1_l2(l1=0.001, l2=0.001),\n",
    "                recurrent_dropout=0.1\n",
    "            ),\n",
    "            input_shape=input_shape\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Second Bidirectional LSTM layer\n",
    "        Bidirectional(\n",
    "            LSTM(\n",
    "                64,\n",
    "                return_sequences=False,\n",
    "                kernel_regularizer=l1_l2(l1=0.001, l2=0.001),\n",
    "                recurrent_dropout=0.1\n",
    "            )\n",
    "        ),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        \n",
    "        # Dense layers\n",
    "        Dense(64, activation='relu', kernel_regularizer=l1_l2(l1=0.0005, l2=0.0005)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Dense(16, activation='relu'),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    \n",
    "    # Compile with Huber loss (robust to outliers)\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=config['learning_rate'],\n",
    "        clipnorm=1.0  # Gradient clipping\n",
    "    )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='huber',  # Robust to outliers\n",
    "        metrics=['mae', 'mse']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"âœ… Model architecture function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "callbacks-header",
   "metadata": {},
   "source": [
    "## ðŸ“Š Comprehensive Training Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "setup-callbacks",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_callbacks(config):\n",
    "    \"\"\"\n",
    "    Create comprehensive callbacks for training\n",
    "    \"\"\"\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    callbacks = [\n",
    "        # 1. Early Stopping\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=config['patience_early_stop'],\n",
    "            restore_best_weights=True,\n",
    "            verbose=1,\n",
    "            mode='min'\n",
    "        ),\n",
    "        \n",
    "        # 2. Reduce Learning Rate on Plateau\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=config['patience_reduce_lr'],\n",
    "            min_lr=1e-7,\n",
    "            verbose=1,\n",
    "            mode='min'\n",
    "        ),\n",
    "        \n",
    "        # 3. Model Checkpoint (save best model)\n",
    "        ModelCheckpoint(\n",
    "            filepath=os.path.join(CHECKPOINT_DIR, f'best_model_{timestamp}.h5'),\n",
    "            monitor='val_loss',\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            verbose=1,\n",
    "            mode='min'\n",
    "        ),\n",
    "        \n",
    "        # 4. CSV Logger (detailed training history)\n",
    "        CSVLogger(\n",
    "            filename=os.path.join(LOGS_DIR, f'training_log_{timestamp}.csv'),\n",
    "            append=False\n",
    "        ),\n",
    "        \n",
    "        # 5. TensorBoard (optional, for visualization)\n",
    "        TensorBoard(\n",
    "            log_dir=os.path.join(LOGS_DIR, f'tensorboard_{timestamp}'),\n",
    "            histogram_freq=1,\n",
    "            write_graph=True\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Callbacks configured:\")\n",
    "    print(f\"   âœ“ Early Stopping (patience={config['patience_early_stop']})\")\n",
    "    print(f\"   âœ“ Reduce LR on Plateau (patience={config['patience_reduce_lr']})\")\n",
    "    print(f\"   âœ“ Model Checkpoint\")\n",
    "    print(f\"   âœ“ CSV Logger\")\n",
    "    print(f\"   âœ“ TensorBoard\")\n",
    "    \n",
    "    return callbacks, timestamp\n",
    "\n",
    "print(\"âœ… Callbacks function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## ðŸš€ Model Training with Progress Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bilstm(model, data, config, callbacks):\n",
    "    \"\"\"\n",
    "    Train BiLSTM model with comprehensive monitoring\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸš€ STARTING MODEL TRAINING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    training_start = datetime.now()\n",
    "    \n",
    "    history = model.fit(\n",
    "        data['X_train'], data['y_train'],\n",
    "        validation_split=config['validation_split'],\n",
    "        epochs=config['epochs'],\n",
    "        batch_size=config['batch_size'],\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    training_duration = datetime.now() - training_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"âœ… TRAINING COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"   Duration: {training_duration}\")\n",
    "    print(f\"   Epochs completed: {len(history.history['loss'])}\")\n",
    "    print(f\"   Best val_loss: {min(history.history['val_loss']):.4f}\")\n",
    "    print(f\"   Best val_mae: {min(history.history['val_mae']):.4f}\")\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "print(\"âœ… Training function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892e6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXED VERSION - Use this instead of the previous save_complete_model function\n",
    "def save_complete_model(model, data, config, history, timestamp):\n",
    "    \"\"\"\n",
    "    Save model in multiple formats with metadata (Keras 3 compatible)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ’¾ SAVING MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_name = f\"{config['model_name']}_v{config['version']}_{timestamp}\"\n",
    "    \n",
    "    # 1. Save full model (.h5 format)\n",
    "    h5_path = os.path.join(MODEL_DIR, f'{model_name}.h5')\n",
    "    model.save(h5_path)\n",
    "    print(f\"âœ… Model saved (HDF5): {h5_path}\")\n",
    "    \n",
    "    # 2. Save model in native Keras format (Keras 3 format)\n",
    "    keras_path = os.path.join(MODEL_DIR, f'{model_name}.keras')\n",
    "    model.save(keras_path)\n",
    "    print(f\"âœ… Model saved (Keras format): {keras_path}\")\n",
    "    \n",
    "    # 3. Save model weights only\n",
    "    weights_path = os.path.join(MODEL_DIR, f'{model_name}_weights.h5')\n",
    "    model.save_weights(weights_path)\n",
    "    print(f\"âœ… Weights saved: {weights_path}\")\n",
    "    \n",
    "    # 4. Save model architecture (JSON)\n",
    "    architecture_path = os.path.join(METADATA_DIR, f'{model_name}_architecture.json')\n",
    "    with open(architecture_path, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    print(f\"âœ… Architecture saved: {architecture_path}\")\n",
    "    \n",
    "    # 5. Save training history\n",
    "    history_path = os.path.join(METADATA_DIR, f'{model_name}_history.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    print(f\"âœ… Training history saved: {history_path}\")\n",
    "    \n",
    "    # 6. Save metadata (configuration + performance)\n",
    "    metadata = {\n",
    "        'model_name': model_name,\n",
    "        'timestamp': timestamp,\n",
    "        'config': config,\n",
    "        'training_info': {\n",
    "            'total_epochs': len(history.history['loss']),\n",
    "            'best_val_loss': float(min(history.history['val_loss'])),\n",
    "            'best_val_mae': float(min(history.history['val_mae'])),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_train_mae': float(history.history['mae'][-1]),\n",
    "        },\n",
    "        'data_info': {\n",
    "            'n_features': len(data['feature_names']),\n",
    "            'n_train_samples': int(data['X_train'].shape[0]),\n",
    "            'n_test_samples': int(data['X_test'].shape[0]),\n",
    "            'target_mean': float(data['y_train'].mean()),\n",
    "            'target_std': float(data['y_train'].std()),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(METADATA_DIR, f'{model_name}_metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    print(f\"âœ… Metadata saved: {metadata_path}\")\n",
    "    \n",
    "    # 7. Create a \"latest\" symlink or copy\n",
    "    latest_path = os.path.join(MODEL_DIR, 'latest_model.h5')\n",
    "    import shutil\n",
    "    shutil.copy2(h5_path, latest_path)\n",
    "    print(f\"âœ… Latest model link created: {latest_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸŽ‰ MODEL SAVED SUCCESSFULLY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nðŸ“¦ Saved artifacts:\")\n",
    "    print(f\"   1. Full model (.h5): {h5_path}\")\n",
    "    print(f\"   2. Keras format (.keras): {keras_path}\")\n",
    "    print(f\"   3. Weights only: {weights_path}\")\n",
    "    print(f\"   4. Architecture (JSON): {architecture_path}\")\n",
    "    print(f\"   5. Training history: {history_path}\")\n",
    "    print(f\"   6. Metadata: {metadata_path}\")\n",
    "    print(f\"   7. Latest model: {latest_path}\")\n",
    "    \n",
    "    return model_name, metadata\n",
    "\n",
    "print(\"âœ… FIXED Model saving function defined - ready to use!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Comprehensive Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_complete_model(model, data, config, history, timestamp):\n",
    "    \"\"\"\n",
    "    Save model in multiple formats with metadata\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ’¾ SAVING MODEL\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    model_name = f\"{config['model_name']}_v{config['version']}_{timestamp}\"\n",
    "    \n",
    "    # 1. Save full model (.h5 format)\n",
    "    h5_path = os.path.join(MODEL_DIR, f'{model_name}.h5')\n",
    "    model.save(h5_path)\n",
    "    print(f\"âœ… Model saved (HDF5): {h5_path}\")\n",
    "    \n",
    "    # 2. Save model in SavedModel format (TensorFlow)\n",
    "    savedmodel_path = os.path.join(MODEL_DIR, f'{model_name}_savedmodel')\n",
    "    model.save(savedmodel_path, save_format='tf')\n",
    "    print(f\"âœ… Model saved (SavedModel): {savedmodel_path}\")\n",
    "    \n",
    "    # 3. Save model weights only\n",
    "    weights_path = os.path.join(MODEL_DIR, f'{model_name}_weights.h5')\n",
    "    model.save_weights(weights_path)\n",
    "    print(f\"âœ… Weights saved: {weights_path}\")\n",
    "    \n",
    "    # 4. Save model architecture (JSON)\n",
    "    architecture_path = os.path.join(METADATA_DIR, f'{model_name}_architecture.json')\n",
    "    with open(architecture_path, 'w') as f:\n",
    "        f.write(model.to_json())\n",
    "    print(f\"âœ… Architecture saved: {architecture_path}\")\n",
    "    \n",
    "    # 5. Save training history\n",
    "    history_path = os.path.join(METADATA_DIR, f'{model_name}_history.pkl')\n",
    "    with open(history_path, 'wb') as f:\n",
    "        pickle.dump(history.history, f)\n",
    "    print(f\"âœ… Training history saved: {history_path}\")\n",
    "    \n",
    "    # 6. Save metadata (configuration + performance)\n",
    "    metadata = {\n",
    "        'model_name': model_name,\n",
    "        'timestamp': timestamp,\n",
    "        'config': config,\n",
    "        'training_info': {\n",
    "            'total_epochs': len(history.history['loss']),\n",
    "            'best_val_loss': float(min(history.history['val_loss'])),\n",
    "            'best_val_mae': float(min(history.history['val_mae'])),\n",
    "            'final_train_loss': float(history.history['loss'][-1]),\n",
    "            'final_train_mae': float(history.history['mae'][-1]),\n",
    "        },\n",
    "        'data_info': {\n",
    "            'n_features': len(data['feature_names']),\n",
    "            'n_train_samples': int(data['X_train'].shape[0]),\n",
    "            'n_test_samples': int(data['X_test'].shape[0]),\n",
    "            'target_mean': float(data['y_train'].mean()),\n",
    "            'target_std': float(data['y_train'].std()),\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    metadata_path = os.path.join(METADATA_DIR, f'{model_name}_metadata.json')\n",
    "    with open(metadata_path, 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    print(f\"âœ… Metadata saved: {metadata_path}\")\n",
    "    \n",
    "    # 7. Create a \"latest\" symlink or copy\n",
    "    latest_path = os.path.join(MODEL_DIR, 'latest_model.h5')\n",
    "    import shutil\n",
    "    shutil.copy2(h5_path, latest_path)\n",
    "    print(f\"âœ… Latest model link created: {latest_path}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸŽ‰ MODEL SAVED SUCCESSFULLY\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nðŸ“¦ Saved artifacts:\")\n",
    "    print(f\"   1. Full model (.h5): {h5_path}\")\n",
    "    print(f\"   2. SavedModel format: {savedmodel_path}\")\n",
    "    print(f\"   3. Weights only: {weights_path}\")\n",
    "    print(f\"   4. Architecture (JSON): {architecture_path}\")\n",
    "    print(f\"   5. Training history: {history_path}\")\n",
    "    print(f\"   6. Metadata: {metadata_path}\")\n",
    "    print(f\"   7. Latest model: {latest_path}\")\n",
    "    \n",
    "    return model_name, metadata\n",
    "\n",
    "print(\"âœ… Model saving function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## ðŸ“Š Model Evaluation & Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_comprehensive(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Comprehensive model evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ðŸ“Š MODEL EVALUATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test, verbose=0).flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Median absolute error\n",
    "    median_ae = np.median(np.abs(y_test - y_pred))\n",
    "    \n",
    "    # Mean Absolute Percentage Error (handle division by zero)\n",
    "    mape = np.mean(np.abs((y_test - y_pred) / np.where(y_test != 0, y_test, 1))) * 100\n",
    "    \n",
    "    # Prediction accuracy at different thresholds\n",
    "    within_3_days = np.mean(np.abs(y_test - y_pred) <= 3) * 100\n",
    "    within_7_days = np.mean(np.abs(y_test - y_pred) <= 7) * 100\n",
    "    within_14_days = np.mean(np.abs(y_test - y_pred) <= 14) * 100\n",
    "    within_30_days = np.mean(np.abs(y_test - y_pred) <= 30) * 100\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Core Metrics:\")\n",
    "    print(f\"   MAE (Mean Absolute Error):      {mae:.2f} days\")\n",
    "    print(f\"   RMSE (Root Mean Squared Error): {rmse:.2f} days\")\n",
    "    print(f\"   RÂ² Score:                       {r2:.4f}\")\n",
    "    print(f\"   Median Absolute Error:          {median_ae:.2f} days\")\n",
    "    print(f\"   MAPE:                           {mape:.2f}%\")\n",
    "    \n",
    "    print(f\"\\nðŸŽ¯ Prediction Accuracy:\")\n",
    "    print(f\"   Within  3 days:  {within_3_days:5.1f}%\")\n",
    "    print(f\"   Within  7 days:  {within_7_days:5.1f}%\")\n",
    "    print(f\"   Within 14 days:  {within_14_days:5.1f}%\")\n",
    "    print(f\"   Within 30 days:  {within_30_days:5.1f}%\")\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = y_test - y_pred\n",
    "    print(f\"\\nðŸ“ˆ Error Distribution:\")\n",
    "    print(f\"   Mean error:      {errors.mean():6.2f} days\")\n",
    "    print(f\"   Std error:       {errors.std():6.2f} days\")\n",
    "    print(f\"   Min error:       {errors.min():6.2f} days\")\n",
    "    print(f\"   25th percentile: {np.percentile(errors, 25):6.2f} days\")\n",
    "    print(f\"   50th percentile: {np.percentile(errors, 50):6.2f} days\")\n",
    "    print(f\"   75th percentile: {np.percentile(errors, 75):6.2f} days\")\n",
    "    print(f\"   Max error:       {errors.max():6.2f} days\")\n",
    "    \n",
    "    results = {\n",
    "        'predictions': y_pred,\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'r2': r2,\n",
    "        'median_ae': median_ae,\n",
    "        'mape': mape,\n",
    "        'within_3': within_3_days,\n",
    "        'within_7': within_7_days,\n",
    "        'within_14': within_14_days,\n",
    "        'within_30': within_30_days,\n",
    "        'errors': errors\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"âœ… Evaluation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "viz-header",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualizations",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot training history\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Loss\n",
    "    axes[0, 0].plot(history.history['loss'], label='Train Loss', linewidth=2)\n",
    "    axes[0, 0].plot(history.history['val_loss'], label='Val Loss', linewidth=2)\n",
    "    axes[0, 0].set_title('Model Loss', fontsize=14, fontweight='bold')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MAE\n",
    "    axes[0, 1].plot(history.history['mae'], label='Train MAE', linewidth=2)\n",
    "    axes[0, 1].plot(history.history['val_mae'], label='Val MAE', linewidth=2)\n",
    "    axes[0, 1].set_title('Mean Absolute Error', fontsize=14, fontweight='bold')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('MAE (days)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # MSE\n",
    "    axes[1, 0].plot(history.history['mse'], label='Train MSE', linewidth=2)\n",
    "    axes[1, 0].plot(history.history['val_mse'], label='Val MSE', linewidth=2)\n",
    "    axes[1, 0].set_title('Mean Squared Error', fontsize=14, fontweight='bold')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('MSE')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Learning Rate (if available)\n",
    "    if 'lr' in history.history:\n",
    "        axes[1, 1].plot(history.history['lr'], linewidth=2, color='red')\n",
    "        axes[1, 1].set_title('Learning Rate', fontsize=14, fontweight='bold')\n",
    "        axes[1, 1].set_xlabel('Epoch')\n",
    "        axes[1, 1].set_ylabel('Learning Rate')\n",
    "        axes[1, 1].set_yscale('log')\n",
    "        axes[1, 1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… Training history plot saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(y_test, y_pred, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot predictions vs actual\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Scatter plot\n",
    "    axes[0].scatter(y_test, y_pred, alpha=0.5, s=20)\n",
    "    axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                'r--', lw=2, label='Perfect Prediction')\n",
    "    axes[0].set_xlabel('Actual Days', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Predicted Days', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Predictions vs Actual', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Error distribution\n",
    "    errors = y_test - y_pred\n",
    "    axes[1].hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[1].axvline(x=0, color='r', linestyle='--', linewidth=2, label='Zero Error')\n",
    "    axes[1].set_xlabel('Prediction Error (days)', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Error Distribution', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"âœ… Predictions plot saved: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "print(\"âœ… Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-header",
   "metadata": {},
   "source": [
    "## ðŸ”„ Model Loading & Inference Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_complete_model(model_path=None):\n",
    "    \"\"\"\n",
    "    Load a saved model with all its components\n",
    "    \"\"\"\n",
    "    \n",
    "    if model_path is None:\n",
    "        model_path = os.path.join(MODEL_DIR, 'latest_model.h5')\n",
    "    \n",
    "    print(f\"\\nðŸ“‚ Loading model from: {model_path}\")\n",
    "    \n",
    "    # Load model\n",
    "    model = load_model(model_path)\n",
    "    print(\"âœ… Model loaded successfully\")\n",
    "    \n",
    "    # Load scaler\n",
    "    scaler_path = os.path.join(SCALER_DIR, 'feature_scaler.pkl')\n",
    "    with open(scaler_path, 'rb') as f:\n",
    "        scaler = pickle.load(f)\n",
    "    print(f\"âœ… Scaler loaded from: {scaler_path}\")\n",
    "    \n",
    "    # Load feature names\n",
    "    feature_path = os.path.join(METADATA_DIR, 'feature_names.json')\n",
    "    with open(feature_path, 'r') as f:\n",
    "        feature_names = json.load(f)\n",
    "    print(f\"âœ… Feature names loaded from: {feature_path}\")\n",
    "    \n",
    "    return {\n",
    "        'model': model,\n",
    "        'scaler': scaler,\n",
    "        'feature_names': feature_names\n",
    "    }\n",
    "\n",
    "def predict_new_data(model_components, new_data):\n",
    "    \"\"\"\n",
    "    Make predictions on new data\n",
    "    \n",
    "    Args:\n",
    "        model_components: dict with 'model', 'scaler', 'feature_names'\n",
    "        new_data: DataFrame with features\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract required features\n",
    "    X_new = new_data[model_components['feature_names']]\n",
    "    \n",
    "    # Scale features\n",
    "    X_scaled = model_components['scaler'].transform(X_new)\n",
    "    \n",
    "    # Reshape for LSTM\n",
    "    X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "    \n",
    "    # Predict\n",
    "    predictions = model_components['model'].predict(X_lstm, verbose=0).flatten()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "print(\"âœ… Loading and inference functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline-header",
   "metadata": {},
   "source": [
    "## ðŸš€ COMPLETE PIPELINE EXECUTION\n",
    "### Run this section to train and save your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "main-pipeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "MAIN EXECUTION PIPELINE\n",
    "\n",
    "Uncomment and run this section to:\n",
    "1. Load your data\n",
    "2. Create enhanced features\n",
    "3. Train BiLSTM model\n",
    "4. Save model in multiple formats\n",
    "5. Evaluate performance\n",
    "6. Generate visualizations\n",
    "\"\"\"\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df = pd.read_excel('soya_data_cleaned_2023_onwards.xlsx')\n",
    "\n",
    "# Convert date columns\n",
    "date_columns = ['sales_order_creation_date', 'promised_expedition_date', 'actual_expedition_date', 'date_and_time_expedition']\n",
    "for col in date_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "print(f\"Dataset shape before combining batches: {df.shape}\")\n",
    "print(f\"Date range: {df['actual_expedition_date'].min()} to {df['actual_expedition_date'].max()}\")\n",
    "\n",
    "# Combine orders with same client_order_number (delivered in batches)\n",
    "print(f\"\\nTotal records before combining batches: {len(df)}\")\n",
    "print(f\"Unique client_order_numbers: {df['client_order_number'].nunique()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df['client_order_number'].duplicated().sum()\n",
    "print(f\"Orders delivered in multiple batches: {duplicates}\")\n",
    "\n",
    "# Group by client_order_number and aggregate:\n",
    "# - actual_expedition_date: take the LAST date (max) - when final batch was delivered\n",
    "# - total_amount_delivered_tm: SUM all batches\n",
    "# - other fields: take first (they should be the same for the same order)\n",
    "agg_dict = {\n",
    "    'sales_order_creation_date': 'first',\n",
    "    'actual_expedition_date': 'max',  # Last delivery date\n",
    "    'total_amount_delivered_tm': 'sum',  # Sum all batches\n",
    "    'client_name': 'first',\n",
    "}\n",
    "\n",
    "# Add any other columns that exist in the dataframe\n",
    "for col in df.columns:\n",
    "    if col not in agg_dict and col != 'client_order_number':\n",
    "        agg_dict[col] = 'first'\n",
    "\n",
    "df = df.groupby('client_order_number', as_index=False).agg(agg_dict)\n",
    "\n",
    "print(f\"After combining batches: {len(df)} unique orders\")\n",
    "print()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902488ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create order size categories\n",
    "df['order_size_category'] = pd.cut(\n",
    "    df['total_amount_delivered_tm'],\n",
    "    bins=[0, 5, 10, 20, np.inf],\n",
    "    labels=['Small', 'Medium', 'Large', 'Extra Large'],\n",
    "    include_lowest=True\n",
    ")\n",
    "\n",
    "print(\"Order Size Distribution:\")\n",
    "print(df['order_size_category'].value_counts())\n",
    "print(f\"\\nPercentage:\")\n",
    "print(df['order_size_category'].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5221375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Small and Medium orders only\n",
    "df_filtered = df[df['order_size_category'].isin(['Small', 'Medium'])].copy()\n",
    "\n",
    "print(f\"Original dataset: {len(df)} records\")\n",
    "print(f\"Filtered dataset (Small + Medium): {len(df_filtered)} records\")\n",
    "print(f\"\\nCategory breakdown:\")\n",
    "print(df_filtered['order_size_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea21b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create features\n",
    "df_features = create_enhanced_features(df_filtered)\n",
    "print(\"âš ï¸  Step 2: Create features\")\n",
    "\n",
    "# Step 3: Select features\n",
    "selected_features = select_best_features()\n",
    "print(\"âš ï¸  Step 3: Select features\")\n",
    "\n",
    "# Step 4: Prepare data\n",
    "data = prepare_data_for_lstm(df_features, selected_features, CONFIG)\n",
    "print(\"âš ï¸  Step 4: Prepare data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558b5562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Build model\n",
    "input_shape = (data['X_train'].shape[1], data['X_train'].shape[2])\n",
    "model = build_enhanced_bilstm(input_shape, CONFIG)\n",
    "print(model.summary())\n",
    "print(\"âš ï¸  Step 5: Build model\")\n",
    "\n",
    "# Step 6: Create callbacks\n",
    "callbacks, timestamp = create_callbacks(CONFIG)\n",
    "print(\"âš ï¸  Step 6: Create callbacks\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedb5c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train model\n",
    "model, history = train_bilstm(model, data, CONFIG, callbacks)\n",
    "print(\"âš ï¸  Step 7: Train model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905bf2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Step 8: Save model\n",
    "# model_name, metadata = save_complete_model(model, data, CONFIG, history, timestamp)\n",
    "# print(\"âš ï¸  Step 8: Save model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab629289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Evaluate\n",
    "results = evaluate_model_comprehensive(model, data['X_test'], data['y_test'])\n",
    "print(\"âš ï¸  Step 9: Evaluate model\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ff8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Visualize\n",
    "plot_training_history(history, save_path='training_history.png')\n",
    "plot_predictions(data['y_test'], results['predictions'], save_path='predictions.png')\n",
    "print(\"âš ï¸  Step 10: Create visualizations\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inference-header",
   "metadata": {},
   "source": [
    "## ðŸ”® Quick Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "QUICK INFERENCE EXAMPLE\n",
    "\n",
    "Use this to load a saved model and make predictions\n",
    "\"\"\"\n",
    "\n",
    "# Load the latest saved model\n",
    "model_components = load_complete_model()\n",
    "\n",
    "# Make predictions on new data\n",
    "predictions = predict_new_data(model_components, new_df)\n",
    "\n",
    "print(f\"Predictions: {predictions}\")\n",
    "\n",
    "print(\"\\nâœ… Inference example ready!\")\n",
    "print(\"\\nUncomment to load model and make predictions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Summary\n",
    "\n",
    "### Your Current Performance (Excellent! ðŸŽ‰)\n",
    "- **MAE: 3.59 days** (Much better than baseline 6.17 days)\n",
    "- **Within 7 days: 91.9%** (Outstanding!)\n",
    "- **Within 14 days: 96.3%** (Excellent precision)\n",
    "\n",
    "### What This Notebook Provides\n",
    "\n",
    "1. **Enhanced Architecture**\n",
    "   - Bidirectional LSTM (128 â†’ 64 units)\n",
    "   - Batch normalization\n",
    "   - L1/L2 regularization\n",
    "   - Dropout for regularization\n",
    "\n",
    "2. **Comprehensive Model Saving**\n",
    "   - âœ… Full model (.h5)\n",
    "   - âœ… SavedModel format (TensorFlow)\n",
    "   - âœ… Weights only\n",
    "   - âœ… Architecture (JSON)\n",
    "   - âœ… Training history\n",
    "   - âœ… Metadata\n",
    "   - âœ… Scaler\n",
    "   - âœ… Feature names\n",
    "\n",
    "3. **Training Features**\n",
    "   - Early stopping\n",
    "   - Learning rate reduction\n",
    "   - Model checkpointing\n",
    "   - CSV logging\n",
    "   - TensorBoard support\n",
    "\n",
    "4. **Easy Inference**\n",
    "   - Simple model loading\n",
    "   - Prediction on new data\n",
    "   - All preprocessing handled automatically\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Load your data\n",
    "2. Run the pipeline\n",
    "3. Model will be saved automatically\n",
    "4. Use `load_complete_model()` for inference\n",
    "5. Share the `models/` directory for deployment\n",
    "\n",
    "**Your model is already performing excellently! This notebook helps you save and deploy it properly.** ðŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
